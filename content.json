[{"title":"test tags","date":"2017-03-02T10:40:06.000Z","path":"2017/03/02/test-tags/","text":"9 Recommender Systems9.1 9.2 Problems9.2.1 Movies Alice - θ(1) Bob - θ(2) Carol - θ(3) Dave - θ(4) romance - x1 action -x2 Love at last 5 5 0 0 1.0 0.0 Romance forever 5 ? ? 0 0.9 0.1 Cute puppies of love 5 4 0 ? 0.99 0.01 Nonstop car chases 0 0 5 4 0.0 1.0 Sword vs. karate 0 0 5 ? 0.2 0.8 9.2.2 PurposeActually, we can assume that we have known all features about the all movies, that is x1, x2, …, xn. And we want to initiate some random values for all theta for all users. As the feature values was fixed, we training the training set by minimizing cost function to get right value of theta. 9.3 Algorithm9.3.1 Optimization Objective 9.3.2 Gradient descent update12345Question: 1. Why we don&apos;t need (1/m) Anwser: As there are only ***one user*** 2. Reguration Answer: (λ/1) = λ 9.3.3 Gradient descent in Logistic Regression 12Question: However, in the above example, we have known the values of all features, but for sometime, we have no idea about that. It means that we have to *** learn theta and features at the same time *** 9.4 Collaborative filtering9.4.1 Proble motivation Movies Alice - θ(1) Bob - θ(2) Carol - θ(3) Dave - θ(4) romance - x1 action - x2 x(1) - Love at last 5 5 0 0 ? ? x(2) -Romance forever 5 ? ? 0 ? ? x(3) -Cute puppies of love 5 4 0 ? ? ? x(4) -Nonstop car chases 0 0 5 4 ? ? x(5) -Sword vs. karate 0 0 5 ? ? ? 9.4.2 How to do12Question: How can we get the value of x? Assume:$$\\theta^{(1)} = \\begin{bmatrix} 0 \\ 5 \\ 0 \\end{bmatrix}, \\space\\space\\theta^{(2)} = \\begin{bmatrix} 0 \\ 5 \\ 0 \\end{bmatrix}, \\space\\space\\theta^{(3)} = \\begin{bmatrix} 0 \\ 0 \\ 5 \\end{bmatrix}, \\space\\space\\theta^{(4)} = \\begin{bmatrix} 0 \\ 0 \\ 5 \\end{bmatrix}, \\space\\spacex^{(1)} = \\begin{bmatrix} 1 \\ 1.0 \\ 0.0 \\end{bmatrix}$$For Movie 1, we can calculate the result of Movie1 rating by all users.$$\\theta^{(1)} x^{(1)} \\approx 5 \\\\theta^{(2)} x^{(1)} \\approx 5 \\\\theta^{(3)} x^{(1)} \\approx 0 \\\\theta^{(4)} x^{(1)} \\approx 0$$ 9.4.3 Optimization Algorithm12345Idea: For a given value of theta, we can minimize the cost function to learn the value of xi For a given value of xi, we can also do that to learn the value of theata. θ --&gt; x --&gt; θ --&gt; x --&gt; θ --&gt; x --&gt; θ --&gt; x --&gt; ... But this two steps, we shoud do that *** simultaneously *** Origional Algorithm Collaborative filterin Optimization Algorithm ​","tags":[{"name":"Macine Learning","slug":"Macine-Learning","permalink":"http://chenson.com/tags/Macine-Learning/"},{"name":"Stanford","slug":"Stanford","permalink":"http://chenson.com/tags/Stanford/"}]},{"title":"Machine","date":"2017-03-02T10:16:14.000Z","path":"2017/03/02/Machine/","text":"9 Recommender Systems9.1 9.2 Problems9.2.1 Movies Alice - θ(1) Bob - θ(2) Carol - θ(3) Dave - θ(4) romance - x1 action -x2 Love at last 5 5 0 0 1.0 0.0 Romance forever 5 ? ? 0 0.9 0.1 Cute puppies of love 5 4 0 ? 0.99 0.01 Nonstop car chases 0 0 5 4 0.0 1.0 Sword vs. karate 0 0 5 ? 0.2 0.8 9.2.2 PurposeActually, we can assume that we have known all features about the all movies, that is x1, x2, …, xn. And we want to initiate some random values for all theta for all users. As the feature values was fixed, we training the training set by minimizing cost function to get right value of theta. 9.3 Algorithm9.3.1 Optimization Objective 9.3.2 Gradient descent update12345Question: 1. Why we don&apos;t need (1/m) Anwser: As there are only ***one user*** 2. Reguration Answer: (λ/1) = λ 9.3.3 Gradient descent in Logistic Regression 12Question: However, in the above example, we have known the values of all features, but for sometime, we have no idea about that. It means that we have to *** learn theta and features at the same time *** 9.4 Collaborative filtering9.4.1 Proble motivation Movies Alice - θ(1) Bob - θ(2) Carol - θ(3) Dave - θ(4) romance - x1 action - x2 x(1) - Love at last 5 5 0 0 ? ? x(2) -Romance forever 5 ? ? 0 ? ? x(3) -Cute puppies of love 5 4 0 ? ? ? x(4) -Nonstop car chases 0 0 5 4 ? ? x(5) -Sword vs. karate 0 0 5 ? ? ? 9.4.2 How to do12Question: How can we get the value of x? Assume:$$\\theta^{(1)} = \\begin{bmatrix} 0 \\ 5 \\ 0 \\end{bmatrix}, \\space\\space\\theta^{(2)} = \\begin{bmatrix} 0 \\ 5 \\ 0 \\end{bmatrix}, \\space\\space\\theta^{(3)} = \\begin{bmatrix} 0 \\ 0 \\ 5 \\end{bmatrix}, \\space\\space\\theta^{(4)} = \\begin{bmatrix} 0 \\ 0 \\ 5 \\end{bmatrix}, \\space\\spacex^{(1)} = \\begin{bmatrix} 1 \\ 1.0 \\ 0.0 \\end{bmatrix}$$For Movie 1, we can calculate the result of Movie1 rating by all users.$$\\theta^{(1)} x^{(1)} \\approx 5 \\\\theta^{(2)} x^{(1)} \\approx 5 \\\\theta^{(3)} x^{(1)} \\approx 0 \\\\theta^{(4)} x^{(1)} \\approx 0$$ 9.4.3 Optimization Algorithm12345Idea: For a given value of theta, we can minimize the cost function to learn the value of xi For a given value of xi, we can also do that to learn the value of theata. θ --&gt; x --&gt; θ --&gt; x --&gt; θ --&gt; x --&gt; θ --&gt; x --&gt; ... But this two steps, we shoud do that *** simultaneously *** Origional Algorithm Collaborative filterin Optimization Algorithm ​","tags":[]},{"title":"Hello World","date":"2017-03-02T07:30:08.000Z","path":"2017/03/02/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]