[{"title":"Machine Learning Week9 - Recommender Systems ","date":"2017-03-02T11:05:21.000Z","path":"2017/03/02/Machine-Learning-Week9-Recommender-Systems/","text":"9 Recommender Systems9.1 What is Recommender Systems对于推荐系统的定义，我们先举几个例子来理解一下。 电影网站给用户推荐电影，可以根据该用户以往的评分，比如给浪漫爱情电影评分高，给动作片评分较低，那么系统可以根据这些信息，给用户推荐偏向浪漫爱情的电影 如果是新用户呢？我们没有该用户的评分信息。那么我们可以根据整个系统中，某些电影评分较高进行推荐 那么如果是新网站，新用户呢？ 以上例子，我们可以把推荐系统分成两类。 Content-based systems Content-based，就是基于已有的信息进行推荐。具体哪些信息呢？在上面的电影推荐系统中，有两类信息需要分析。 第一，是User的评分信息，比如给爱情片评分高，给动作片评分低。 第二，是Movie的特征信息，比如这部电影偏向爱情片多一些，但也有一部分搞笑。所以在A（爱情片）和B（搞笑片）中， A的权重更高，B的较低 基于以上两部分信息，我们可以给用户推荐他所喜欢的电影。 Collaborative filterring systems 协同过滤器，则是基于用户/物品之间的相似度进行推荐的。即用户A和用户B都喜欢爱情、浪漫电影，我们就可以把用户A评分过的爱情浪漫电影，推荐给用户B。 9.2 Content-based systems9.2.1 Problem Analysis以电影推荐系统为例，假设我们已经对系统中的电影特征有了较为完善，即我们知道某部电影属于爱情片多少分，属于动作片多少分。 那么我们现在以Alice为例，她对两部爱情片评分比较高，对于两部动作片评分为0。那么系统就可以给Alice推荐偏向爱情浪漫的，且不怎么属于动作片的电影。 Movies Alice - θ(1) Bob - θ(2) Carol - θ(3) Dave - θ(4) romance - x1 action -x2 Love at last 5 5 0 0 1.0 0.0 Romance forever 5 ? ? 0 0.9 0.1 Cute puppies of love ？ 4 0 ? 0.99 0.01 Nonstop car chases 0 0 5 4 0.0 1.0 Sword vs. karate 0 0 5 ? 0.2 0.8 9.2.2 Optimization Objective实际上我们已经假设之前对所有电影的特征进行了统计，所以此时有电影特征向量X，以及用户对于电影的评分Y向量。根据此时已有的信息，我们需要求出theta的值。所以能够对于那么没有评分过的电影，根据theta和x求出分数y。 因为一开始theat的值是随机的，所以我们用Linear Regression的方法，不断减少cost function的值求出theta。 值得注意的是，因为这里是多个用户，每一个用户我们求出一个theta值。最后对于多个用户，我们需要求出多个theta值。 Actually, we can assume that we have known all features about the all movies, that is x1, x2, …, xn. And we want to initiate some random values for all theta for all users. As the feature values was fixed, we training the training set by minimizing cost function to get right value of theta. 9.2.2 Gradient descent update 9.2.3 Gradient descent in Logistic Regression Question: Why we don’t need (1/m)? Anwser: As there are only one user However, in the above example, we have known the values of all features, but for sometime, we have no idea about that. It means that we have to learn theta and features at the same time 9.3 Collaborative filtering9.3.1 Proble motivation Movies Alice - θ(1) Bob - θ(2) Carol - θ(3) Dave - θ(4) romance - x1 action - x2 x(1) - Love at last 5 5 0 0 ? ? x(2) -Romance forever 5 ? ? 0 ? ? x(3) -Cute puppies of love ? 4 0 ? ? ? x(4) -Nonstop car chases 0 0 5 4 ? ? x(5) -Sword vs. karate 0 0 5 ? ? ? 9.3.2 How to do 在之前部分中，我们了解到了content-based，是已知 x 和 y，求 theta。 Assume:$$\\theta^{(1)} = \\begin{bmatrix} 0 \\ 5 \\ 0 \\end{bmatrix}, \\space\\space\\theta^{(2)} = \\begin{bmatrix} 0 \\ 5 \\ 0 \\end{bmatrix}, \\space\\space\\theta^{(3)} = \\begin{bmatrix} 0 \\ 0 \\ 5 \\end{bmatrix}, \\space\\space\\theta^{(4)} = \\begin{bmatrix} 0 \\ 0 \\ 5 \\end{bmatrix}, \\space\\spacex^{(1)} = \\begin{bmatrix} 1 \\ 1.0 \\ 0.0 \\end{bmatrix}$$For Movie 1, we can calculate the result of Movie1 rating by all users.$$\\theta^{(1)} x^{(1)} \\approx 5 \\\\theta^{(2)} x^{(1)} \\approx 5 \\\\theta^{(3)} x^{(1)} \\approx 0 \\\\theta^{(4)} x^{(1)} \\approx 0$$ 但是对于有些情况，我们并不知道x的特征值，该怎么办呢？ 逆向思考，我们也可以通过 theat 和 y，来求 x 的值。 那么对于 theta和x的值都不知道的情况下呢？ 对比特征 Linear Regression Collaborative filtering 特性向量X 已知数据 待求解数据 权重 θ 待求解数据 待求解数据 y值 已知数据 已知数据 9.3.3 Optimization Algorithm For a given value of theta, we can minimize the cost function to learn the value of xi For a given value of xi, we can also do that to learn the value of theata. $$θ -&gt; x -&gt; θ -&gt; x -&gt; θ -&gt; x -&gt; θ -&gt; x -&gt; …$$ Actually, these two steps are Linear Regression, we shoud do that simultaneously to update theta and x. 9.3.4 Collaborative filtering Optimization Algorithm 实际上，上面是两个 LR的问题，我们可以将上面两步合并到一起，这个就是collaborative filterring， 此时的optimizatino object 就从 J(theta) 和 J(X) 变为了 J(theta, X)。 具体步骤如下 9.3.5 Vectorization: Low rank matrix factorization首先，我们先把评分Y用向量表示出来，同时表示为Theta和X两个矩阵的乘积$$Y= \\begin{bmatrix} 5 &amp; 5 &amp; 0 &amp; 0 \\ 5 &amp; ? &amp; ?&amp; 0 \\ ? &amp; 4 &amp; 0 &amp; ? \\ 0 &amp; 0 &amp; 5 &amp; 4 \\ 0 &amp; 0 &amp; 5 &amp; 0\\end{bmatrix} =\\begin{bmatrix}(\\theta^{(1)})^T(x^{(1)}) &amp; (\\theta^{(2)})^T(x^{(1)}) &amp; … &amp; (\\theta^{(n_u)})^T(x^{(1)}) \\(\\theta^{(1)})^T(x^{(2)}) &amp; (\\theta^{(2)})^T(x^{(2)}) &amp; … &amp; (\\theta^{(n_u)})^T(x^{(2)}) \\… &amp; … &amp; … &amp; … \\(\\theta^{(1)})^T(x^{(n_m)}) &amp; (\\theta^{(2)})^T(x^{(n_m)}) &amp; … &amp; (\\theta^{(n_u)})^T(x^{(n_m)})\\end{bmatrix} = X * \\Theta’, R \\in (n_m × n_u)$$ $$X = \\begin{bmatrix}—(x^{(1)})^T— \\—(x^{(2)})^T— \\… \\—(x^{(n_m)})^T—\\end{bmatrix},x^{(n_m)} = \\begin{bmatrix}x^{(n_m)}_1 \\ x^{(n_m)}_2 \\ … \\ x^{(n_m)}_n\\end{bmatrix}, R \\in (n_m × n)$$ $$\\Theta = \\begin{bmatrix}—(\\theta^{(1)})^T— \\—(\\theta^{(2)})^T— \\… \\—(\\theta^{(n_u)})^T—\\end{bmatrix},\\theta^{(n_u)} = \\begin{bmatrix}\\theta^{(n_u)}_1 \\ \\theta^{(n_u)}_2 \\ … \\ \\theta^{(n_u)}_n\\end{bmatrix}, R \\in (n_u × n)$$ 9.3.6 Mean Normalization对于那些新注册用户，系统中没有记录他们的偏好，则采用以下方法。 先计算出每部电影评分的平均值mu，然后把所有的评分都减去平均值（此后处理过的评分平均值为0）。虽然这样做对有评分记录用户是多余的，但却可以吧没有评分记录的用户给统一进来，避免全是0的情况。 9.4 Implement Algorithm9.4.1 Cost Function without Regularization Tips：这里需要计算的只是针对那些已经评分过的电影，对于用户没有评分过的不需要计算。 9.4.2 Collaborative filtering gradient$$\\frac {\\partial J} {\\partial x_k^{(1)}} , \\frac {\\partial J} {\\partial x_k^{(2)}} , …, \\frac {\\partial J} {\\partial x_k^{(n_m)}} \\space\\space for \\space each \\space movie\\\\frac {\\partial J} {\\partial \\theta_k^{(1)}} , \\frac {\\partial J} {\\partial \\theta_k^{(2)}} , …, \\frac {\\partial J} {\\partial \\theta_k^{(n_u)}} \\space\\space for \\space each \\space user$$Tips： 对于使用vectorization方法，最终只有两个for-loop，一个计算X_grad，一个计算Theta_grad 如何对X和Theta求偏导数？ $$(Theta_{grad}(i, :))^T = \\begin{bmatrix}\\frac {\\partial J} {\\partial \\theta^{(i)}_1} \\\\frac {\\partial J} {\\partial \\theta^{(i)}_2} \\… \\\\frac {\\partial J} {\\partial \\theta^{(i)}_n}\\end{bmatrix}$$ 同样，我们只需考虑用户已经评分过的电影，用其作为训练样本 因为Vectorization非常容易搞乱各个matrix，所以建议先整理一下各个matrix的size，计算时可以根据matrix的size进行计算。 9.4.3 Implementation注意这里并没有给出完整的代码 (Octave/Matlab)，都只是主要的部分。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950% Theta : nu x n% X : nm x n% Y : nm x nu% R : nm x nupred = X * Theta&apos;; %nm x nu &apos;diff = pred - Y;% Cost Function with regularizationJ = 0.5 * sum(sum((diff.^2) .* R));J = J + (lambda * 0.5) * sum(sum(Theta.^2)); % regularized term of theta.J = J + (lambda * 0.5) * sum(sum(X.^2)); % regularized term of x.% calculate Xfor i = 1 : num_movies, % the row vector of all users that have rated movie i idx = find(R(i, :) == 1); % (1 * r) % the list of users who have rated on movie i Theta_temp = Theta(idx, :); % (r * n) Y_temp = Y(i, idx); % (1 * r) X_temp = X(i, :); % (1 * n) % ((1 * n) * (n * r) -(1 * r)) * (r * n) = (1 * n) X_grad(i, :) = (X_temp * Theta_temp&apos; - Y_temp) * Theta_temp; %&apos; % regularization X_grad(i, :) = X_grad(i, :) + lambda * X_temp;end% calculate Thetafor i = 1 : num_users, % the row vector of all movies that user i has rated idx = find(R(:, i) == 1)&apos;; % (1 * r) &apos; Theta_temp = Theta(i, :); % (1 * n) Y_temp = Y(idx, i); % (r * 1) X_temp = X(idx, :); % (r * n) % ((r * n) * (n * 1) - (r * 1)) * (r * n) = (1 * n) Theta_grad(i, :) = (X_temp * Theta_temp&apos; - Y_temp)&apos; * X_temp; % regularization Theta_grad(i, :) = Theta_grad(i, :) + lambda * Theta_temp;endgrad = [X_grad(:); Theta_grad(:)]; ​​​","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://chenson.com/tags/Machine-Learning/"}]},{"title":"Machine Learning Week7 - SVM","date":"2017-03-02T11:02:59.000Z","path":"2017/03/02/Machine-Learning-Week7-SVM/","text":"7 SVM - Support Vector Machine7. 1 Optimisation Objective$$h_\\theta (x) = \\frac 1 {1 + e^{-\\theta^Tx}} \\z = -\\theta^Tx$$ Why we need do that? 7.2 Hypothesis Function7.2.1 Logistic Regression$$\\frac 1 m \\sum{i=1}^m [ y^{(i)} * (-log(h\\theta(x^{(i)})) + (1 - y^{(i)}) * (-log(1 - h\\theta(x^{(i)}))) ] + \\frac \\lambda {2m} \\sum{j=1}^n \\theta_j^2$$ 7.2.2 Support Vector Machine$$C \\sum_{i=1}^m [y^{(i)} cost_1(\\theta^Tx^{(i)}) + (1 - y^{(i)}) cost0(\\theta^Tx^{(i)})] + \\frac 1 2 \\sum{j=1}^n \\theta_j^2,\\space \\space \\space \\space \\space C = \\frac 1 \\lambda$$ Analysis： 为了使得cost function取得最小值，我们令C*W + P部分中，C*W为零。即： 当 y = 1时， cost1 = 0，所以 z &gt;= 1 当 y = 0时， cost0 = 0，所以 z &lt;= -1 Note：1. cost0 and cost1 对应的是上图中左右两边的cost function，因为y=0和y=1的目标函数。 常数C取一个很大的值时比较好。因为C*W + P， 所以C大则W会变小，即相对penality就会变大，W会变小 为什么要重新选定一个cost function ？（逻辑回归的临界点为0，但是SVM的临界点是1，所以SVM更加精确。 ） 对应的线性逻辑回归？即次数不大于1的？ Decision Boundary 不是一条直线的情况 7.3 Large Margin Classifier12结论：常数C取一个比较大的值比较容易获得Large Margin ClassifierC大，则比较容易获得 以上为两类分布比较均匀的时候，Decision Boundary为图中黑色的线，所有点离黑色的距离都相对比较大比较均匀，但是当存在干扰点的时候如下图，Decision Boundary会由黑色变为粉红色。所以C的取值不能太大，也不能太小。需要求出最优解 7.4 Mathmatics Behind Large Margin Classification7.4.1 Vector Inner Product Note： 如何求投影p的值？ 当角度 &lt; 90°，p为正数。当角度 &gt; 90°时，p为负数。 $$向量内积：u^Tv = ||u|| · ||v|| · cosθ = ||u|| · p{v,u} = ||v|| · p{u,v} = u_1v_1+u_2v_2$$ 7.4.2 SVM Cost Function$$C \\sum_{i=1}^m [y^{(i)} cost_1(\\theta^Tx^{(i)}) + (1 - y^{(i)}) cost0(\\theta^Tx^{(i)})] + \\frac 1 2 \\sum{j=1}^n \\theta_j^2,\\space \\space \\space \\space \\space C = \\frac 1 \\lambda$$ 当C取一个一个很大的值时，cost function只剩下后面P的部分。 假设θ0 = 0$$\\frac 1 2 \\sum_{j=1}^n\\theta^2_j = \\frac 1 2 (\\theta^2_0 + \\theta^2_1 + … + \\theta^2_n) = \\frac 1 2 (\\theta^2_1 + … + \\theta^2_n)= \\frac 1 2 ||\\theta||^2$$ 所以：$$\\theta^Tx^{(i)} = p^{(i)}||\\theta|| \\p^{(i)}||\\theta|| &gt;= 1, if \\space\\space y^{(i)} = 1 \\p^{(i)}||\\theta|| &lt;= -1, if \\space\\space y^{(i)} = 0 \\p^{(i)}是点到向量\\theta的projection，即点到Decision Boundary的距离$$上面我们讨论了，当C取到一个合适的、较大的数值时，SVM的cost function就只剩下后面P的部分，即$$\\frac 1 2 ||\\theta||^2$$我们要减小cost function，所以需要减小θ的值。 当θ取到一个比较小的值的时候，还需要满足上面讨论的：$$\\theta^Tx^{(i)} = p^{(i)}||\\theta|| \\p^{(i)}||\\theta|| &gt;= 1, if \\space\\space y^{(i)} = 1 \\p^{(i)}||\\theta|| &lt;= -1, if \\space\\space y^{(i)} = 0 \\$$所以θ比较小时，只能增加p的值去满足p*||θ|| &gt;= 1 或者 p*||θ||&lt;= -1。 这样就保证了p的值比较大，即点到Decision Boundary的大间距。 7.5 Kernels7.5.1 Kernels &amp; Similarity首先，我们回想一下之前的logistic regression中对于non-linear 情况的拟合。 Predict y = 1, if$$\\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\theta_3x_3x_2 + \\theta_4x_1^2 + \\theta_5x_2^2 + … &gt;= 0 \\\\theta_0 + \\theta_1f_1 + \\theta_2f_2 + \\theta_3f_3 + \\theta_4f_4 + \\theta_5f_5 + … &gt;= 0$$即将fn定义为x的幂次项组合，如下：$$f_1 = x_1, f_2 = x_2, f_3 = x_1x_2, f_4 = x_1^2, f_5 = x_2^2, …$$ 但是在SVM中，我们要重新定义fn，引入Kernel的概念，即用 kernel function来表示fn。 Note: l 是landmark，且如果training sets里面的数量为n的话，则landmark的数量也为n。 假设training sets数量为n，则对于一个新的example来说，可计算出n个新的特征f1…fn。然后用新的特征，对该example进行判断（低维转为高维的过程） kernel function为guassian function。当x与landmark l越接近时，两点的距离越小，值接近1 7.5.2 SVM with Kernels 对比之前的cost function，可以发现这里θ和f(x)跟之前的不同。 在logistic regression 中，θ的维度为(n+1) x 1, 包含θ0， 且n为单个example的特征个数 在SVM with kernel中，f(x)的个数为m，其中m是training sets中的个数，所以θ的维度应该是(m+1)x1 Steps 给定一组training sets，根据每个example，选取m个landmark点 计算每一个example与所有landmark的相识度，相同为1，非常不同接近为0。计算相识度的kernel function为Gaussian Function 最终，对于每一个example里面都可以计算出m个新的feature，所以对于这个training sets而言，会得到一个m*m的矩阵？ 将得到的m*m的矩阵，代入到Hypothesis中，计算出θ的值。 7.5.4 SVM parameters C $$C = \\frac 1 \\lambda$$ Large C Small λ Large θ Lower Bias High Variance Over Fitting Small C Large λ Small θ Higher Bias Low Variance Under Fitting σ | Large σ | more smoothly | Higher Bias | Lower Variance | Under Fitting || ———– | —————– | ————– | ——————- | —————- || Small σ | less smoothly | Lower Bias | Higher Variance | Over Fitting | ​","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://chenson.com/tags/Machine-Learning/"},{"name":"SVM","slug":"SVM","permalink":"http://chenson.com/tags/SVM/"}]}]