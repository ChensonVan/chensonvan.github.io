[{"title":"Hadoop权威指南笔记（一）","date":"2017-03-06T13:44:33.000Z","path":"2017/03/07/Hadoop权威指南笔记（一）/","text":"1. Hadoop1.1 初识Hadoop非常好的Tutorial 在学习hadoop之前，我觉得有必要了解一下hadoop的基本构成以及一些术语。 Block HDFS blocks are large compared to disk blocks, and the reason is to minimize the costof seeks. By making a block large enough, the time to transfer the data from the diskcan be made to be significantly larger than the time to seek to the start of the block.Thus the time to transfer a large file made of multiple blocks operates at the disk transferrate.A quick calculation shows that if the seek time is around 10 ms, and the transfer rateis 100 MB/s, then to make the seek time 1% of the transfer time, we need to make theblock size around 100 MB. The default is actually 64 MB, although many HDFS installationsuse 128 MB blocks. This figure will continue to be revised upward as transferspeeds grow with new generations of disk drives.This argument shouldn’t be taken too far, however. Map tasks in MapReduce normallyoperate on one block at a time, so if you have too few tasks (fewer than nodes in thecluster), your jobs will run slower than they could otherwise. Node 简单的说就是一台主机，一台电脑。在hadoop中，有NameNode, DataNode, Secondary NameNode, JobTracker Node, TaskTracker Node, CheckpointNode 和 BackupNode。对一个cluster，NameNode只能有一个，DataNode可以有多个 Rack 中文机柜/机架，就是用来存放node的storage，通常一个rack有几十个nodes组成，这些nodes存放在同一个机柜，连接一个交换机 A Node is simply a computer. This is typically non-enterprise, commodity hardware for nodes that contain data. Storage of Nodes is called as rack. A rack is a collection of 30 or 40 nodes that are physically stored close together and are all connected to the same network switch. Network bandwidth between any two nodes in rack is greater than bandwidth between two nodes on different racks.A Hadoop Cluster is a collection of racks. 1.2 Major Components Distributed Filesystem — hadoop中是HDFS MapReduce 1.5 Install configuration123456# 待整理hadoop fshadoop dfs# fs refers to any file system, it oucld be local or HDFS# but dfs refers to only HDFS file system 2. MapReduce2.1 初识MapReduce 整个过程可以分为三个阶段，Input， MapReduce and Output 在input和output阶段，数据是存在HDFS文件系统中，其系统的block size大小默认是64/128MB。 在MapReduce中，又可以分为两个阶段，Map and Reduce，数据从map function到reduce function是存在local disk中，(soreing in HDFS with replication would be overkill)，然后通过network传输数据. 在每个阶段中，input和output的数据都是以 (key, values) 格式进行处理的，然后通过 map function 和 reduce function 进行处理。在本例中，input data的key是从数据文件开始处的行数的偏移量，但是map function输出的key是年份数据，以及reduce function输出的key是也不同的。所以这三个key-value pairs是不同的。 原始数据 Key-Values 以上为原始数据中input进来后的key-values的数据。然后map function阶段，提取出上面文件中的 1950 和 0001 之类的数据，组成新的key-values作为输出给下一阶段。 Key-Values in Map Function 在将Map Function的输出传给Reduce Function之前，实际上MapReduce Framework还是有对数据进行一个处理步骤。从最上的图一中，我们仍然可以看到Map和Reduce之间有一个 Shuffle 的过程。因为之前我们提到了，Map的过程中，只是实现了一个key-value匹配的过程，所有出来的数据也是无序的，而 Shuffle 就是对这个输出 sort &amp; group 的过程，然后将输出传给 Reduce Function 进行处理 当数据从Reduce Function中处理完后出来的大概如下，注意这个reduce只是选择最大值，其他reduce function可能做的是统计或者实现其他功能。 现在再看另外一个经典的WordCount的例子 在Hadoop系统中，处理一个wordcount的任务可以大致分成四个主要阶段，input，map，reduce，output。其中 Map 和 Reduce 可以继续细分，即分成多个 map tasks 和 reduce tasks。 这些tasks然后被 YARN 给分配集群中多台不同的机器处理。这其中的细节等到往后再讨论。 上面提到的分成多个tasks时，应该是input data切片分给多个maps（而不是一个大的map分成多个小的tasks）， 每个MapReduce分到一个fixed-sized 的数据，通常是64/128MB，这个过程叫做 input splits。然后每个split分配一个map task，同时运行在不同的机器上处理。这样划分的好处是有利于load-balancing，对于性能较好的机器可以处理更过是splits。 2.2 Data Flow 上图可以看出hadoop的整个数据流向，其中虚线代表是在一个node，实线代表的是不同node之间。在同一个node之间，数据的读取存储就有速度上的优势，不同node之间，也就是不同主机之间，就必须通过network进行传输，速度较慢。 Partition 当只有一个reduce的时候，map function的output当然就直接传给这个reduce了。但是当有多个reduce的时候，怎么办呢？此时map会将其输出进行partition(分区)，每一个reduce的任务都会创建一个分区，且每一个reduce task都会有一个partition (There can be many keys (and their associated values)in each partition, but the records for any given key are all in a single partition)，也就是说同一个key会在同一个partition中。 Shuffle and Sort 在map和reduce之间的data flow是Shuffle，从上图可以看出，一个reduce可以接受来自多个不同的map的output，其中包含了sort，partition等过程。 Combiner Functions 之前我们讨论过，data flow在map和reduce之间是通过network进行传输的，但我们知道map function的output是一个个key-value的键值对的，这些key-value paris中，有些是可以通过combiner function进行combine的，这样做的目的是减小map和reduce之间传输的数据大小，加快传输数据。 Combiner Function在许多情况和 Reduce Function是很像的，因为做的工作和reduce是比较类似的，只是处理的是局部map的output(因此Combiner是运行在map output端)，减少data flow的size。但是对于是否调用combiner function，这个是不确定的。因为有些情况下的output是不适合进行combine，有些则又是要多次调用进行合并。对于有些特殊情况，甚至连reduce function都不需要。 举个栗子： 适用情况（Commutative &amp; Associative） ​ Reduce Function Combiner Function ​ Commutative: max(a, b) = max(b, a) ​ Associative: max(max(a, b), c) = max(a, max(b, c)) 不适用情况：","tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://chenson.com/tags/Hadoop/"},{"name":"MapReduce","slug":"MapReduce","permalink":"http://chenson.com/tags/MapReduce/"}]},{"title":"Machine Learning Week9 - Recommender Systems ","date":"2017-03-02T11:05:21.000Z","path":"2017/03/02/Machine-Learning-Week9-Recommender-Systems/","text":"9 Recommender Systems9.1 What is Recommender Systems对于推荐系统的定义，我们先举几个例子来理解一下。 电影网站给用户推荐电影，可以根据该用户以往的评分，比如给浪漫爱情电影评分高，给动作片评分较低，那么系统可以根据这些信息，给用户推荐偏向浪漫爱情的电影 如果是新用户呢？我们没有该用户的评分信息。那么我们可以根据整个系统中，某些电影评分较高进行推荐 那么如果是新网站，新用户呢？ 以上例子，我们可以把推荐系统分成两类。 Content-based systems Content-based，就是基于已有的信息进行推荐。具体哪些信息呢？在上面的电影推荐系统中，有两类信息需要分析。 第一，是User的评分信息，比如给爱情片评分高，给动作片评分低。 第二，是Movie的特征信息，比如这部电影偏向爱情片多一些，但也有一部分搞笑。所以在A（爱情片）和B（搞笑片）中， A的权重更高，B的较低 基于以上两部分信息，我们可以给用户推荐他所喜欢的电影。 Collaborative filterring systems 协同过滤器，则是基于用户/物品之间的相似度进行推荐的。即用户A和用户B都喜欢爱情、浪漫电影，我们就可以把用户A评分过的爱情浪漫电影，推荐给用户B。 9.2 Content-based systems9.2.1 Problem Analysis以电影推荐系统为例，假设我们已经对系统中的电影特征有了较为完善，即我们知道某部电影属于爱情片多少分，属于动作片多少分。 那么我们现在以Alice为例，她对两部爱情片评分比较高，对于两部动作片评分为0。那么系统就可以给Alice推荐偏向爱情浪漫的，且不怎么属于动作片的电影。 Movies Alice - θ(1) Bob - θ(2) Carol - θ(3) Dave - θ(4) romance - x1 action -x2 Love at last 5 5 0 0 1.0 0.0 Romance forever 5 ? ? 0 0.9 0.1 Cute puppies of love ？ 4 0 ? 0.99 0.01 Nonstop car chases 0 0 5 4 0.0 1.0 Sword vs. karate 0 0 5 ? 0.2 0.8 9.2.2 Optimization Objective实际上我们已经假设之前对所有电影的特征进行了统计，所以此时有电影特征向量X，以及用户对于电影的评分Y向量。根据此时已有的信息，我们需要求出theta的值。所以能够对于那么没有评分过的电影，根据theta和x求出分数y。 因为一开始theat的值是随机的，所以我们用Linear Regression的方法，不断减少cost function的值求出theta。 值得注意的是，因为这里是多个用户，每一个用户我们求出一个theta值。最后对于多个用户，我们需要求出多个theta值。 Actually, we can assume that we have known all features about the all movies, that is x1, x2, …, xn. And we want to initiate some random values for all theta for all users. As the feature values was fixed, we training the training set by minimizing cost function to get right value of theta. 9.2.2 Gradient descent update 9.2.3 Gradient descent in Logistic Regression Question: Why we don’t need (1/m)? Anwser: As there are only one user However, in the above example, we have known the values of all features, but for sometime, we have no idea about that. It means that we have to learn theta and features at the same time 9.3 Collaborative filtering9.3.1 Proble motivation Movies Alice - θ(1) Bob - θ(2) Carol - θ(3) Dave - θ(4) romance - x1 action - x2 x(1) - Love at last 5 5 0 0 ? ? x(2) -Romance forever 5 ? ? 0 ? ? x(3) -Cute puppies of love ? 4 0 ? ? ? x(4) -Nonstop car chases 0 0 5 4 ? ? x(5) -Sword vs. karate 0 0 5 ? ? ? 9.3.2 How to do 在之前部分中，我们了解到了content-based，是已知 x 和 y，求 theta。 Assume:$$\\theta^{(1)} = \\begin{bmatrix} 0 \\ 5 \\ 0 \\end{bmatrix}, \\space\\space\\theta^{(2)} = \\begin{bmatrix} 0 \\ 5 \\ 0 \\end{bmatrix}, \\space\\space\\theta^{(3)} = \\begin{bmatrix} 0 \\ 0 \\ 5 \\end{bmatrix}, \\space\\space\\theta^{(4)} = \\begin{bmatrix} 0 \\ 0 \\ 5 \\end{bmatrix}, \\space\\spacex^{(1)} = \\begin{bmatrix} 1 \\ 1.0 \\ 0.0 \\end{bmatrix}$$For Movie 1, we can calculate the result of Movie1 rating by all users.$$\\theta^{(1)} x^{(1)} \\approx 5 \\\\theta^{(2)} x^{(1)} \\approx 5 \\\\theta^{(3)} x^{(1)} \\approx 0 \\\\theta^{(4)} x^{(1)} \\approx 0$$ 但是对于有些情况，我们并不知道x的特征值，该怎么办呢？ 逆向思考，我们也可以通过 theat 和 y，来求 x 的值。 那么对于 theta和x的值都不知道的情况下呢？ 对比特征 Linear Regression Collaborative filtering 特性向量X 已知数据 待求解数据 权重 θ 待求解数据 待求解数据 y值 已知数据 已知数据 9.3.3 Optimization Algorithm For a given value of theta, we can minimize the cost function to learn the value of xi For a given value of xi, we can also do that to learn the value of theata. $$θ -&gt; x -&gt; θ -&gt; x -&gt; θ -&gt; x -&gt; θ -&gt; x -&gt; …$$ Actually, these two steps are Linear Regression, we shoud do that simultaneously to update theta and x. 9.3.4 Collaborative filtering Optimization Algorithm 实际上，上面是两个 LR的问题，我们可以将上面两步合并到一起，这个就是collaborative filterring， 此时的optimizatino object 就从 J(theta) 和 J(X) 变为了 J(theta, X)。 具体步骤如下 9.3.5 Vectorization: Low rank matrix factorization首先，我们先把评分Y用向量表示出来，同时表示为Theta和X两个矩阵的乘积$$Y= \\begin{bmatrix} 5 &amp; 5 &amp; 0 &amp; 0 \\ 5 &amp; ? &amp; ?&amp; 0 \\ ? &amp; 4 &amp; 0 &amp; ? \\ 0 &amp; 0 &amp; 5 &amp; 4 \\ 0 &amp; 0 &amp; 5 &amp; 0\\end{bmatrix} =\\begin{bmatrix}(\\theta^{(1)})^T(x^{(1)}) &amp; (\\theta^{(2)})^T(x^{(1)}) &amp; … &amp; (\\theta^{(n_u)})^T(x^{(1)}) \\(\\theta^{(1)})^T(x^{(2)}) &amp; (\\theta^{(2)})^T(x^{(2)}) &amp; … &amp; (\\theta^{(n_u)})^T(x^{(2)}) \\… &amp; … &amp; … &amp; … \\(\\theta^{(1)})^T(x^{(n_m)}) &amp; (\\theta^{(2)})^T(x^{(n_m)}) &amp; … &amp; (\\theta^{(n_u)})^T(x^{(n_m)})\\end{bmatrix} = X * \\Theta’, R \\in (n_m × n_u)$$ $$X = \\begin{bmatrix}—(x^{(1)})^T— \\—(x^{(2)})^T— \\… \\—(x^{(n_m)})^T—\\end{bmatrix},x^{(n_m)} = \\begin{bmatrix}x^{(n_m)}_1 \\ x^{(n_m)}_2 \\ … \\ x^{(n_m)}_n\\end{bmatrix}, R \\in (n_m × n)$$ $$\\Theta = \\begin{bmatrix}—(\\theta^{(1)})^T— \\—(\\theta^{(2)})^T— \\… \\—(\\theta^{(n_u)})^T—\\end{bmatrix},\\theta^{(n_u)} = \\begin{bmatrix}\\theta^{(n_u)}_1 \\ \\theta^{(n_u)}_2 \\ … \\ \\theta^{(n_u)}_n\\end{bmatrix}, R \\in (n_u × n)$$ 9.3.6 Mean Normalization对于那些新注册用户，系统中没有记录他们的偏好，则采用以下方法。 先计算出每部电影评分的平均值mu，然后把所有的评分都减去平均值（此后处理过的评分平均值为0）。虽然这样做对有评分记录用户是多余的，但却可以吧没有评分记录的用户给统一进来，避免全是0的情况。 9.4 Implement Algorithm9.4.1 Cost Function without Regularization Tips：这里需要计算的只是针对那些已经评分过的电影，对于用户没有评分过的不需要计算。 9.4.2 Collaborative filtering gradient$$\\frac {\\partial J} {\\partial x_k^{(1)}} , \\frac {\\partial J} {\\partial x_k^{(2)}} , …, \\frac {\\partial J} {\\partial x_k^{(n_m)}} \\space\\space for \\space each \\space movie\\\\frac {\\partial J} {\\partial \\theta_k^{(1)}} , \\frac {\\partial J} {\\partial \\theta_k^{(2)}} , …, \\frac {\\partial J} {\\partial \\theta_k^{(n_u)}} \\space\\space for \\space each \\space user$$Tips： 对于使用vectorization方法，最终只有两个for-loop，一个计算X_grad，一个计算Theta_grad 如何对X和Theta求偏导数？ $$(Theta_{grad}(i, :))^T = \\begin{bmatrix}\\frac {\\partial J} {\\partial \\theta^{(i)}_1} \\\\frac {\\partial J} {\\partial \\theta^{(i)}_2} \\… \\\\frac {\\partial J} {\\partial \\theta^{(i)}_n}\\end{bmatrix}$$ 同样，我们只需考虑用户已经评分过的电影，用其作为训练样本 因为Vectorization非常容易搞乱各个matrix，所以建议先整理一下各个matrix的size，计算时可以根据matrix的size进行计算。 9.4.3 Implementation注意这里并没有给出完整的代码 (Octave/Matlab)，都只是主要的部分。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950% Theta : nu x n% X : nm x n% Y : nm x nu% R : nm x nupred = X * Theta&apos;; %nm x nu &apos;diff = pred - Y;% Cost Function with regularizationJ = 0.5 * sum(sum((diff.^2) .* R));J = J + (lambda * 0.5) * sum(sum(Theta.^2)); % regularized term of theta.J = J + (lambda * 0.5) * sum(sum(X.^2)); % regularized term of x.% calculate Xfor i = 1 : num_movies, % the row vector of all users that have rated movie i idx = find(R(i, :) == 1); % (1 * r) % the list of users who have rated on movie i Theta_temp = Theta(idx, :); % (r * n) Y_temp = Y(i, idx); % (1 * r) X_temp = X(i, :); % (1 * n) % ((1 * n) * (n * r) -(1 * r)) * (r * n) = (1 * n) X_grad(i, :) = (X_temp * Theta_temp&apos; - Y_temp) * Theta_temp; %&apos; % regularization X_grad(i, :) = X_grad(i, :) + lambda * X_temp;end% calculate Thetafor i = 1 : num_users, % the row vector of all movies that user i has rated idx = find(R(:, i) == 1)&apos;; % (1 * r) &apos; Theta_temp = Theta(i, :); % (1 * n) Y_temp = Y(idx, i); % (r * 1) X_temp = X(idx, :); % (r * n) % ((r * n) * (n * 1) - (r * 1)) * (r * n) = (1 * n) Theta_grad(i, :) = (X_temp * Theta_temp&apos; - Y_temp)&apos; * X_temp; % regularization Theta_grad(i, :) = Theta_grad(i, :) + lambda * Theta_temp;endgrad = [X_grad(:); Theta_grad(:)]; ​​​","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://chenson.com/tags/Machine-Learning/"}]},{"title":"Machine Learning Week7 - SVM","date":"2017-03-02T11:02:59.000Z","path":"2017/03/02/Machine-Learning-Week7-SVM/","text":"7 SVM - Support Vector Machine7. 1 Optimisation Objective$$h_\\theta (x) = \\frac 1 {1 + e^{-\\theta^Tx}} \\z = -\\theta^Tx$$ Why we need do that? 7.2 Hypothesis Function7.2.1 Logistic Regression$$\\frac 1 m \\sum{i=1}^m [ y^{(i)} * (-log(h\\theta(x^{(i)})) + (1 - y^{(i)}) * (-log(1 - h\\theta(x^{(i)}))) ] + \\frac \\lambda {2m} \\sum{j=1}^n \\theta_j^2$$ 7.2.2 Support Vector Machine$$C \\sum_{i=1}^m [y^{(i)} cost_1(\\theta^Tx^{(i)}) + (1 - y^{(i)}) cost0(\\theta^Tx^{(i)})] + \\frac 1 2 \\sum{j=1}^n \\theta_j^2,\\space \\space \\space \\space \\space C = \\frac 1 \\lambda$$ Analysis： 为了使得cost function取得最小值，我们令C*W + P部分中，C*W为零。即： 当 y = 1时， cost1 = 0，所以 z &gt;= 1 当 y = 0时， cost0 = 0，所以 z &lt;= -1 Note：1. cost0 and cost1 对应的是上图中左右两边的cost function，因为y=0和y=1的目标函数。 常数C取一个很大的值时比较好。因为C*W + P， 所以C大则W会变小，即相对penality就会变大，W会变小 为什么要重新选定一个cost function ？（逻辑回归的临界点为0，但是SVM的临界点是1，所以SVM更加精确。 ） 对应的线性逻辑回归？即次数不大于1的？ Decision Boundary 不是一条直线的情况 7.3 Large Margin Classifier12结论：常数C取一个比较大的值比较容易获得Large Margin ClassifierC大，则比较容易获得 以上为两类分布比较均匀的时候，Decision Boundary为图中黑色的线，所有点离黑色的距离都相对比较大比较均匀，但是当存在干扰点的时候如下图，Decision Boundary会由黑色变为粉红色。所以C的取值不能太大，也不能太小。需要求出最优解 7.4 Mathmatics Behind Large Margin Classification7.4.1 Vector Inner Product Note： 如何求投影p的值？ 当角度 &lt; 90°，p为正数。当角度 &gt; 90°时，p为负数。 $$向量内积：u^Tv = ||u|| · ||v|| · cosθ = ||u|| · p{v,u} = ||v|| · p{u,v} = u_1v_1+u_2v_2$$ 7.4.2 SVM Cost Function$$C \\sum_{i=1}^m [y^{(i)} cost_1(\\theta^Tx^{(i)}) + (1 - y^{(i)}) cost0(\\theta^Tx^{(i)})] + \\frac 1 2 \\sum{j=1}^n \\theta_j^2,\\space \\space \\space \\space \\space C = \\frac 1 \\lambda$$ 当C取一个一个很大的值时，cost function只剩下后面P的部分。 假设θ0 = 0$$\\frac 1 2 \\sum_{j=1}^n\\theta^2_j = \\frac 1 2 (\\theta^2_0 + \\theta^2_1 + … + \\theta^2_n) = \\frac 1 2 (\\theta^2_1 + … + \\theta^2_n)= \\frac 1 2 ||\\theta||^2$$ 所以：$$\\theta^Tx^{(i)} = p^{(i)}||\\theta|| \\p^{(i)}||\\theta|| &gt;= 1, if \\space\\space y^{(i)} = 1 \\p^{(i)}||\\theta|| &lt;= -1, if \\space\\space y^{(i)} = 0 \\p^{(i)}是点到向量\\theta的projection，即点到Decision Boundary的距离$$上面我们讨论了，当C取到一个合适的、较大的数值时，SVM的cost function就只剩下后面P的部分，即$$\\frac 1 2 ||\\theta||^2$$我们要减小cost function，所以需要减小θ的值。 当θ取到一个比较小的值的时候，还需要满足上面讨论的：$$\\theta^Tx^{(i)} = p^{(i)}||\\theta|| \\p^{(i)}||\\theta|| &gt;= 1, if \\space\\space y^{(i)} = 1 \\p^{(i)}||\\theta|| &lt;= -1, if \\space\\space y^{(i)} = 0 \\$$所以θ比较小时，只能增加p的值去满足p*||θ|| &gt;= 1 或者 p*||θ||&lt;= -1。 这样就保证了p的值比较大，即点到Decision Boundary的大间距。 7.5 Kernels7.5.1 Kernels &amp; Similarity首先，我们回想一下之前的logistic regression中对于non-linear 情况的拟合。 Predict y = 1, if$$\\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\theta_3x_3x_2 + \\theta_4x_1^2 + \\theta_5x_2^2 + … &gt;= 0 \\\\theta_0 + \\theta_1f_1 + \\theta_2f_2 + \\theta_3f_3 + \\theta_4f_4 + \\theta_5f_5 + … &gt;= 0$$即将fn定义为x的幂次项组合，如下：$$f_1 = x_1, f_2 = x_2, f_3 = x_1x_2, f_4 = x_1^2, f_5 = x_2^2, …$$ 但是在SVM中，我们要重新定义fn，引入Kernel的概念，即用 kernel function来表示fn。 Note: l 是landmark，且如果training sets里面的数量为n的话，则landmark的数量也为n。 假设training sets数量为n，则对于一个新的example来说，可计算出n个新的特征f1…fn。然后用新的特征，对该example进行判断（低维转为高维的过程） kernel function为guassian function。当x与landmark l越接近时，两点的距离越小，值接近1 7.5.2 SVM with Kernels 对比之前的cost function，可以发现这里θ和f(x)跟之前的不同。 在logistic regression 中，θ的维度为(n+1) x 1, 包含θ0， 且n为单个example的特征个数 在SVM with kernel中，f(x)的个数为m，其中m是training sets中的个数，所以θ的维度应该是(m+1)x1 Steps 给定一组training sets，根据每个example，选取m个landmark点 计算每一个example与所有landmark的相识度，相同为1，非常不同接近为0。计算相识度的kernel function为Gaussian Function 最终，对于每一个example里面都可以计算出m个新的feature，所以对于这个training sets而言，会得到一个m*m的矩阵？ 将得到的m*m的矩阵，代入到Hypothesis中，计算出θ的值。 7.5.4 SVM parameters C $$C = \\frac 1 \\lambda$$ Large C Small λ Large θ Lower Bias High Variance Over Fitting Small C Large λ Small θ Higher Bias Low Variance Under Fitting σ | Large σ | more smoothly | Higher Bias | Lower Variance | Under Fitting || ———– | —————– | ————– | ——————- | —————- || Small σ | less smoothly | Lower Bias | Higher Variance | Over Fitting | ​","tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://chenson.com/tags/Machine-Learning/"},{"name":"SVM","slug":"SVM","permalink":"http://chenson.com/tags/SVM/"}]}]