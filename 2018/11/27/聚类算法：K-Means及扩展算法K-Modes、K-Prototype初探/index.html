<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <link rel="dns-prefetch" href="//cdn.bootcss.com">
  <link rel="dns-prefetch" href="//cdn.mathjax.org">

  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="dns-prefetch" href="http://chenson.cc">
  <title>聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探 | Vane&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="由于最近正在参与的自动化建模平台需要用到这一算法，但sklearn里面的聚类算法只支持数值型的，无法用到类别型的特征上，所以就研究了K-Modes和K-Prototypes这两个算法。具体算法的思想和源码如下。 1. k-Means Algorightm K-Means K-Means++">
<meta name="keywords" content="Cluster">
<meta property="og:type" content="article">
<meta property="og:title" content="聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探">
<meta property="og:url" content="http://chenson.cc/2018/11/27/聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探/index.html">
<meta property="og:site_name" content="Vane&#39;s Blog">
<meta property="og:description" content="由于最近正在参与的自动化建模平台需要用到这一算法，但sklearn里面的聚类算法只支持数值型的，无法用到类别型的特征上，所以就研究了K-Modes和K-Prototypes这两个算法。具体算法的思想和源码如下。 1. k-Means Algorightm K-Means K-Means++">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-11-21T06:59:54.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探">
<meta name="twitter:description" content="由于最近正在参与的自动化建模平台需要用到这一算法，但sklearn里面的聚类算法只支持数值型的，无法用到类别型的特征上，所以就研究了K-Modes和K-Prototypes这两个算法。具体算法的思想和源码如下。 1. k-Means Algorightm K-Means K-Means++">
  
    <link rel="alternative" href="/atom.xml" title="Vane&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/images/favicon.ico">
  
  <link rel="stylesheet" type="text/css" href="/./main.2d7529.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

  

</head>
</html>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/images/tx.jpeg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">Chenson Van</a></h1>
		</hgroup>
		
		<p class="header-subtitle">It&#39;s Never Too Late for Now.</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">Home</a></li>
	        
				<li><a href="/archives">Archives</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">Tags</a>
    			
            
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">About Me</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/ChensonVan" title="github"><i class="icon-github"></i></a>
		        
					<a class="douban" target="_blank" href="https://www.douban.com/people/hi_liash/" title="douban"><i class="icon-douban"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:chenson.van@gmail.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/images/tx.jpeg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">Chenson Van</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>It&#39;s Never Too Late for Now.<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/ChensonVan" title="github"><i class="icon-github"></i></a>
			        
						<a class="douban" target="_blank" href="https://www.douban.com/people/hi_liash/" title="douban"><i class="icon-douban"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:chenson.van@gmail.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">Home</a></li>
		        
					<li style="width: 50%"><a href="/archives">Archives</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            <article id="post-聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探" class="article article-type-post " itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探
    </h1>
  

        
        <a href="/2018/11/27/聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探/" class="archive-article-date">
  	<time datetime="2018-11-27T05:23:30.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-11-27</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>由于最近正在参与的自动化建模平台需要用到这一算法，但sklearn里面的聚类算法只支持数值型的，无法用到类别型的特征上，所以就研究了K-Modes和K-Prototypes这两个算法。具体算法的思想和源码如下。</p>
<h3 id="1-k-Means"><a href="#1-k-Means" class="headerlink" title="1. k-Means"></a>1. k-Means</h3><ul>
<li><strong>Algorightm</strong><ul>
<li>K-Means</li>
<li>K-Means++</li>
</ul>
</li>
</ul>
<a id="more"></a>
<ul>
<li><strong>K-Means</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMeans</span><span class="params">(BaseEstimator, ClusterMixin, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="string">"""K-Means clustering</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Read more in the :ref:`User Guide &lt;k_means&gt;`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_clusters : int, optional, default: 8</span></span><br><span class="line"><span class="string">        The number of clusters to form as well as the number of</span></span><br><span class="line"><span class="string">        centroids to generate.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    init : &#123;'k-means++', 'random' or an ndarray&#125;</span></span><br><span class="line"><span class="string">        Method for initialization, defaults to 'k-means++':</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        'k-means++' : selects initial cluster centers for k-mean</span></span><br><span class="line"><span class="string">        clustering in a smart way to speed up convergence. See section</span></span><br><span class="line"><span class="string">        Notes in k_init for more details.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        'random': choose k observations (rows) at random from data for</span></span><br><span class="line"><span class="string">        the initial centroids.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        If an ndarray is passed, it should be of shape (n_clusters, n_features)</span></span><br><span class="line"><span class="string">        and gives the initial centers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_init : int, default: 10</span></span><br><span class="line"><span class="string">        Number of time the k-means algorithm will be run with different</span></span><br><span class="line"><span class="string">        centroid seeds. The final results will be the best output of</span></span><br><span class="line"><span class="string">        n_init consecutive runs in terms of inertia.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    max_iter : int, default: 300</span></span><br><span class="line"><span class="string">        Maximum number of iterations of the k-means algorithm for a</span></span><br><span class="line"><span class="string">        single run.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    tol : float, default: 1e-4</span></span><br><span class="line"><span class="string">        Relative tolerance with regards to inertia to declare convergence</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    precompute_distances : &#123;'auto', True, False&#125;</span></span><br><span class="line"><span class="string">        Precompute distances (faster but takes more memory).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        'auto' : do not precompute distances if n_samples * n_clusters &gt; 12</span></span><br><span class="line"><span class="string">        million. This corresponds to about 100MB overhead per job using</span></span><br><span class="line"><span class="string">        double precision.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        True : always precompute distances</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        False : never precompute distances</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    verbose : int, default 0</span></span><br><span class="line"><span class="string">        Verbosity mode.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    random_state : int, RandomState instance or None (default)</span></span><br><span class="line"><span class="string">        Determines random number generation for centroid initialization. Use</span></span><br><span class="line"><span class="string">        an int to make the randomness deterministic.</span></span><br><span class="line"><span class="string">        See :term:`Glossary &lt;random_state&gt;`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    copy_x : boolean, optional</span></span><br><span class="line"><span class="string">        When pre-computing distances it is more numerically accurate to center</span></span><br><span class="line"><span class="string">        the data first.  If copy_x is True (default), then the original data is</span></span><br><span class="line"><span class="string">        not modified, ensuring X is C-contiguous.  If False, the original data</span></span><br><span class="line"><span class="string">        is modified, and put back before the function returns, but small</span></span><br><span class="line"><span class="string">        numerical differences may be introduced by subtracting and then adding</span></span><br><span class="line"><span class="string">        the data mean, in this case it will also not ensure that data is</span></span><br><span class="line"><span class="string">        C-contiguous which may cause a significant slowdown.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_jobs : int</span></span><br><span class="line"><span class="string">        The number of jobs to use for the computation. This works by computing</span></span><br><span class="line"><span class="string">        each of the n_init runs in parallel.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        If -1 all CPUs are used. If 1 is given, no parallel computing code is</span></span><br><span class="line"><span class="string">        used at all, which is useful for debugging. For n_jobs below -1,</span></span><br><span class="line"><span class="string">        (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one</span></span><br><span class="line"><span class="string">        are used.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    algorithm : "auto", "full" or "elkan", default="auto"</span></span><br><span class="line"><span class="string">        K-means algorithm to use. The classical EM-style algorithm is "full".</span></span><br><span class="line"><span class="string">        The "elkan" variation is more efficient by using the triangle</span></span><br><span class="line"><span class="string">        inequality, but currently doesn't support sparse data. "auto" chooses</span></span><br><span class="line"><span class="string">        "elkan" for dense data and "full" for sparse data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    cluster_centers_ : array, [n_clusters, n_features]</span></span><br><span class="line"><span class="string">        Coordinates of cluster centers</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    labels_ :</span></span><br><span class="line"><span class="string">        Labels of each point</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    inertia_ : float</span></span><br><span class="line"><span class="string">        Sum of squared distances of samples to their closest cluster center.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples</span></span><br><span class="line"><span class="string">    --------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; from sklearn.cluster import KMeans</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; import numpy as np</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; X = np.array([[1, 2], [1, 4], [1, 0],</span></span><br><span class="line"><span class="string">    ...               [4, 2], [4, 4], [4, 0]])</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; kmeans = KMeans(n_clusters=2, random_state=0).fit(X)</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; kmeans.labels_</span></span><br><span class="line"><span class="string">    array([0, 0, 0, 1, 1, 1], dtype=int32)</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; kmeans.predict([[0, 0], [4, 4]])</span></span><br><span class="line"><span class="string">    array([0, 1], dtype=int32)</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt; kmeans.cluster_centers_</span></span><br><span class="line"><span class="string">    array([[1., 2.],</span></span><br><span class="line"><span class="string">           [4., 2.]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    See also</span></span><br><span class="line"><span class="string">    --------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    MiniBatchKMeans</span></span><br><span class="line"><span class="string">        Alternative online implementation that does incremental updates</span></span><br><span class="line"><span class="string">        of the centers positions using mini-batches.</span></span><br><span class="line"><span class="string">        For large scale learning (say n_samples &gt; 10k) MiniBatchKMeans is</span></span><br><span class="line"><span class="string">        probably much faster than the default batch implementation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Notes</span></span><br><span class="line"><span class="string">    ------</span></span><br><span class="line"><span class="string">    The k-means problem is solved using Lloyd's algorithm.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The average complexity is given by O(k n T), were n is the number of</span></span><br><span class="line"><span class="string">    samples and T is the number of iteration.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The worst case complexity is given by O(n^(k+2/p)) with</span></span><br><span class="line"><span class="string">    n = n_samples, p = n_features. (D. Arthur and S. Vassilvitskii,</span></span><br><span class="line"><span class="string">    'How slow is the k-means method?' SoCG2006)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    In practice, the k-means algorithm is very fast (one of the fastest</span></span><br><span class="line"><span class="string">    clustering algorithms available), but it falls in local minima. That's why</span></span><br><span class="line"><span class="string">    it can be useful to restart it several times.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_clusters=<span class="number">8</span>, init=<span class="string">'k-means++'</span>, n_init=<span class="number">10</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 max_iter=<span class="number">300</span>, tol=<span class="number">1e-4</span>, precompute_distances=<span class="string">'auto'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 verbose=<span class="number">0</span>, random_state=None, copy_x=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                 n_jobs=<span class="number">1</span>, algorithm=<span class="string">'auto'</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.n_clusters = n_clusters</span><br><span class="line">        self.init = init</span><br><span class="line">        self.max_iter = max_iter</span><br><span class="line">        self.tol = tol</span><br><span class="line">        self.precompute_distances = precompute_distances</span><br><span class="line">        self.n_init = n_init</span><br><span class="line">        self.verbose = verbose</span><br><span class="line">        self.random_state = random_state</span><br><span class="line">        self.copy_x = copy_x</span><br><span class="line">        self.n_jobs = n_jobs</span><br><span class="line">        self.algorithm = algorithm</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_check_test_data</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        X = check_array(X, accept_sparse=<span class="string">'csr'</span>, dtype=FLOAT_DTYPES)</span><br><span class="line">        n_samples, n_features = X.shape</span><br><span class="line">        expected_n_features = self.cluster_centers_.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> n_features == expected_n_features:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"Incorrect number of features. "</span></span><br><span class="line">                             <span class="string">"Got %d features, expected %d"</span> % (</span><br><span class="line">                                 n_features, expected_n_features))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None, sample_weight=None)</span>:</span></span><br><span class="line">        <span class="string">"""Compute k-means clustering.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : array-like or sparse matrix, shape=(n_samples, n_features)</span></span><br><span class="line"><span class="string">            Training instances to cluster. It must be noted that the data</span></span><br><span class="line"><span class="string">            will be converted to C ordering, which will cause a memory</span></span><br><span class="line"><span class="string">            copy if the given data is not C-contiguous.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        y : Ignored</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        sample_weight : array-like, shape (n_samples,), optional</span></span><br><span class="line"><span class="string">            The weights for each observation in X. If None, all observations</span></span><br><span class="line"><span class="string">            are assigned equal weight (default: None)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        random_state = check_random_state(self.random_state)</span><br><span class="line"></span><br><span class="line">        self.cluster_centers_, self.labels_, self.inertia_, self.n_iter_ = \</span><br><span class="line">            k_means(</span><br><span class="line">                X, n_clusters=self.n_clusters, sample_weight=sample_weight,</span><br><span class="line">                init=self.init, n_init=self.n_init,</span><br><span class="line">                max_iter=self.max_iter, verbose=self.verbose,</span><br><span class="line">                precompute_distances=self.precompute_distances,</span><br><span class="line">                tol=self.tol, random_state=random_state, copy_x=self.copy_x,</span><br><span class="line">                n_jobs=self.n_jobs, algorithm=self.algorithm,</span><br><span class="line">                return_n_iter=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit_predict</span><span class="params">(self, X, y=None, sample_weight=None)</span>:</span></span><br><span class="line">        <span class="string">"""Compute cluster centers and predict cluster index for each sample.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Convenience method; equivalent to calling fit(X) followed by</span></span><br><span class="line"><span class="string">        predict(X).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like, sparse matrix&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            New data to transform.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        y : Ignored</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        sample_weight : array-like, shape (n_samples,), optional</span></span><br><span class="line"><span class="string">            The weights for each observation in X. If None, all observations</span></span><br><span class="line"><span class="string">            are assigned equal weight (default: None)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        labels : array, shape [n_samples,]</span></span><br><span class="line"><span class="string">            Index of the cluster each sample belongs to.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> self.fit(X, sample_weight=sample_weight).labels_</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit_transform</span><span class="params">(self, X, y=None, sample_weight=None)</span>:</span></span><br><span class="line">        <span class="string">"""Compute clustering and transform X to cluster-distance space.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Equivalent to fit(X).transform(X), but more efficiently implemented.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like, sparse matrix&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            New data to transform.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        y : Ignored</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        sample_weight : array-like, shape (n_samples,), optional</span></span><br><span class="line"><span class="string">            The weights for each observation in X. If None, all observations</span></span><br><span class="line"><span class="string">            are assigned equal weight (default: None)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        X_new : array, shape [n_samples, k]</span></span><br><span class="line"><span class="string">            X transformed in the new space.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># Currently, this just skips a copy of the data if it is not in</span></span><br><span class="line">        <span class="comment"># np.array or CSR format already.</span></span><br><span class="line">        <span class="comment"># XXX This skips _check_test_data, which may change the dtype;</span></span><br><span class="line">        <span class="comment"># we should refactor the input validation.</span></span><br><span class="line">        <span class="keyword">return</span> self.fit(X, sample_weight=sample_weight)._transform(X)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""Transform X to a cluster-distance space.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        In the new space, each dimension is the distance to the cluster</span></span><br><span class="line"><span class="string">        centers.  Note that even if X is sparse, the array returned by</span></span><br><span class="line"><span class="string">        `transform` will typically be dense.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like, sparse matrix&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            New data to transform.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        X_new : array, shape [n_samples, k]</span></span><br><span class="line"><span class="string">            X transformed in the new space.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        check_is_fitted(self, <span class="string">'cluster_centers_'</span>)</span><br><span class="line"></span><br><span class="line">        X = self._check_test_data(X)</span><br><span class="line">        <span class="keyword">return</span> self._transform(X)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_transform</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""guts of transform method; no input validation"""</span></span><br><span class="line">        <span class="keyword">return</span> euclidean_distances(X, self.cluster_centers_)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X, sample_weight=None)</span>:</span></span><br><span class="line">        <span class="string">"""Predict the closest cluster each sample in X belongs to.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        In the vector quantization literature, `cluster_centers_` is called</span></span><br><span class="line"><span class="string">        the code book and each value returned by `predict` is the index of</span></span><br><span class="line"><span class="string">        the closest code in the code book.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like, sparse matrix&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            New data to predict.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        sample_weight : array-like, shape (n_samples,), optional</span></span><br><span class="line"><span class="string">            The weights for each observation in X. If None, all observations</span></span><br><span class="line"><span class="string">            are assigned equal weight (default: None)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        labels : array, shape [n_samples,]</span></span><br><span class="line"><span class="string">            Index of the cluster each sample belongs to.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        check_is_fitted(self, <span class="string">'cluster_centers_'</span>)</span><br><span class="line"></span><br><span class="line">        X = self._check_test_data(X)</span><br><span class="line">        x_squared_norms = row_norms(X, squared=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> _labels_inertia(X, sample_weight, x_squared_norms,</span><br><span class="line">                               self.cluster_centers_)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self, X, y=None, sample_weight=None)</span>:</span></span><br><span class="line">        <span class="string">"""Opposite of the value of X on the K-means objective.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : &#123;array-like, sparse matrix&#125;, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            New data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        y : Ignored</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        sample_weight : array-like, shape (n_samples,), optional</span></span><br><span class="line"><span class="string">            The weights for each observation in X. If None, all observations</span></span><br><span class="line"><span class="string">            are assigned equal weight (default: None)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        score : float</span></span><br><span class="line"><span class="string">            Opposite of the value of X on the K-means objective.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        check_is_fitted(self, <span class="string">'cluster_centers_'</span>)</span><br><span class="line"></span><br><span class="line">        X = self._check_test_data(X)</span><br><span class="line">        x_squared_norms = row_norms(X, squared=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> -_labels_inertia(X, sample_weight, x_squared_norms,</span><br><span class="line">                                self.cluster_centers_)[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>k_means</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_means</span><span class="params">(X, n_clusters, sample_weight=None, init=<span class="string">'k-means++'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">            precompute_distances=<span class="string">'auto'</span>, n_init=<span class="number">10</span>, max_iter=<span class="number">300</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">            verbose=False, tol=<span class="number">1e-4</span>, random_state=None, copy_x=True, n_jobs=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">            algorithm=<span class="string">"auto"</span>, return_n_iter=False)</span>:</span></span><br><span class="line">    <span class="string">"""K-means clustering algorithm.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Read more in the :ref:`User Guide &lt;k_means&gt;`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    X : array-like or sparse matrix, shape (n_samples, n_features)</span></span><br><span class="line"><span class="string">        The observations to cluster. It must be noted that the data</span></span><br><span class="line"><span class="string">        will be converted to C ordering, which will cause a memory copy</span></span><br><span class="line"><span class="string">        if the given data is not C-contiguous.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_clusters : int</span></span><br><span class="line"><span class="string">        The number of clusters to form as well as the number of</span></span><br><span class="line"><span class="string">        centroids to generate.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    sample_weight : array-like, shape (n_samples,), optional</span></span><br><span class="line"><span class="string">        The weights for each observation in X. If None, all observations</span></span><br><span class="line"><span class="string">        are assigned equal weight (default: None)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    init : &#123;'k-means++', 'random', or ndarray, or a callable&#125;, optional</span></span><br><span class="line"><span class="string">        Method for initialization, default to 'k-means++':</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        'k-means++' : selects initial cluster centers for k-mean</span></span><br><span class="line"><span class="string">        clustering in a smart way to speed up convergence. See section</span></span><br><span class="line"><span class="string">        Notes in k_init for more details.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        'random': choose k observations (rows) at random from data for</span></span><br><span class="line"><span class="string">        the initial centroids.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        If an ndarray is passed, it should be of shape (n_clusters, n_features)</span></span><br><span class="line"><span class="string">        and gives the initial centers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        If a callable is passed, it should take arguments X, k and</span></span><br><span class="line"><span class="string">        and a random state and return an initialization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    precompute_distances : &#123;'auto', True, False&#125;</span></span><br><span class="line"><span class="string">        Precompute distances (faster but takes more memory).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        'auto' : do not precompute distances if n_samples * n_clusters &gt; 12</span></span><br><span class="line"><span class="string">        million. This corresponds to about 100MB overhead per job using</span></span><br><span class="line"><span class="string">        double precision.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        True : always precompute distances</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        False : never precompute distances</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_init : int, optional, default: 10</span></span><br><span class="line"><span class="string">        Number of time the k-means algorithm will be run with different</span></span><br><span class="line"><span class="string">        centroid seeds. The final results will be the best output of</span></span><br><span class="line"><span class="string">        n_init consecutive runs in terms of inertia.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    max_iter : int, optional, default 300</span></span><br><span class="line"><span class="string">        Maximum number of iterations of the k-means algorithm to run.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    verbose : boolean, optional</span></span><br><span class="line"><span class="string">        Verbosity mode.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    tol : float, optional</span></span><br><span class="line"><span class="string">        The relative increment in the results before declaring convergence.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    random_state : int, RandomState instance or None (default)</span></span><br><span class="line"><span class="string">        Determines random number generation for centroid initialization. Use</span></span><br><span class="line"><span class="string">        an int to make the randomness deterministic.</span></span><br><span class="line"><span class="string">        See :term:`Glossary &lt;random_state&gt;`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    copy_x : boolean, optional</span></span><br><span class="line"><span class="string">        When pre-computing distances it is more numerically accurate to center</span></span><br><span class="line"><span class="string">        the data first.  If copy_x is True (default), then the original data is</span></span><br><span class="line"><span class="string">        not modified, ensuring X is C-contiguous.  If False, the original data</span></span><br><span class="line"><span class="string">        is modified, and put back before the function returns, but small</span></span><br><span class="line"><span class="string">        numerical differences may be introduced by subtracting and then adding</span></span><br><span class="line"><span class="string">        the data mean, in this case it will also not ensure that data is</span></span><br><span class="line"><span class="string">        C-contiguous which may cause a significant slowdown.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_jobs : int</span></span><br><span class="line"><span class="string">        The number of jobs to use for the computation. This works by computing</span></span><br><span class="line"><span class="string">        each of the n_init runs in parallel.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        If -1 all CPUs are used. If 1 is given, no parallel computing code is</span></span><br><span class="line"><span class="string">        used at all, which is useful for debugging. For n_jobs below -1,</span></span><br><span class="line"><span class="string">        (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one</span></span><br><span class="line"><span class="string">        are used.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    algorithm : "auto", "full" or "elkan", default="auto"</span></span><br><span class="line"><span class="string">        K-means algorithm to use. The classical EM-style algorithm is "full".</span></span><br><span class="line"><span class="string">        The "elkan" variation is more efficient by using the triangle</span></span><br><span class="line"><span class="string">        inequality, but currently doesn't support sparse data. "auto" chooses</span></span><br><span class="line"><span class="string">        "elkan" for dense data and "full" for sparse data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return_n_iter : bool, optional</span></span><br><span class="line"><span class="string">        Whether or not to return the number of iterations.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    centroid : float ndarray with shape (k, n_features)</span></span><br><span class="line"><span class="string">        Centroids found at the last iteration of k-means.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    label : integer ndarray with shape (n_samples,)</span></span><br><span class="line"><span class="string">        label[i] is the code or index of the centroid the</span></span><br><span class="line"><span class="string">        i'th observation is closest to.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    inertia : float</span></span><br><span class="line"><span class="string">        The final value of the inertia criterion (sum of squared distances to</span></span><br><span class="line"><span class="string">        the closest centroid for all observations in the training set).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    best_n_iter : int</span></span><br><span class="line"><span class="string">        Number of iterations corresponding to the best results.</span></span><br><span class="line"><span class="string">        Returned only if `return_n_iter` is set to True.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> n_init &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"Invalid number of initializations."</span></span><br><span class="line">                         <span class="string">" n_init=%d must be bigger than zero."</span> % n_init)</span><br><span class="line">    random_state = check_random_state(random_state)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> max_iter &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Number of iterations should be a positive number,'</span></span><br><span class="line">                         <span class="string">' got %d instead'</span> % max_iter)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># avoid forcing order when copy_x=False</span></span><br><span class="line">    order = <span class="string">"C"</span> <span class="keyword">if</span> copy_x <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">    X = check_array(X, accept_sparse=<span class="string">'csr'</span>, dtype=[np.float64, np.float32],</span><br><span class="line">                    order=order, copy=copy_x)</span><br><span class="line">    <span class="comment"># verify that the number of samples given is larger than k</span></span><br><span class="line">    <span class="keyword">if</span> _num_samples(X) &lt; n_clusters:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"n_samples=%d should be &gt;= n_clusters=%d"</span> % (</span><br><span class="line">            _num_samples(X), n_clusters))</span><br><span class="line"></span><br><span class="line">    tol = _tolerance(X, tol)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># If the distances are precomputed every job will create a matrix of shape</span></span><br><span class="line">    <span class="comment"># (n_clusters, n_samples). To stop KMeans from eating up memory we only</span></span><br><span class="line">    <span class="comment"># activate this if the created matrix is guaranteed to be under 100MB. 12</span></span><br><span class="line">    <span class="comment"># million entries consume a little under 100MB if they are of type double.</span></span><br><span class="line">    <span class="keyword">if</span> precompute_distances == <span class="string">'auto'</span>:</span><br><span class="line">        n_samples = X.shape[<span class="number">0</span>]</span><br><span class="line">        precompute_distances = (n_clusters * n_samples) &lt; <span class="number">12e6</span></span><br><span class="line">    <span class="keyword">elif</span> isinstance(precompute_distances, bool):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"precompute_distances should be 'auto' or True/False"</span></span><br><span class="line">                         <span class="string">", but a value of %r was passed"</span> %</span><br><span class="line">                         precompute_distances)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Validate init array</span></span><br><span class="line">    <span class="keyword">if</span> hasattr(init, <span class="string">'__array__'</span>):</span><br><span class="line">        init = check_array(init, dtype=X.dtype.type, copy=<span class="literal">True</span>)</span><br><span class="line">        _validate_center_shape(X, n_clusters, init)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> n_init != <span class="number">1</span>:</span><br><span class="line">            warnings.warn(</span><br><span class="line">                <span class="string">'Explicit initial center position passed: '</span></span><br><span class="line">                <span class="string">'performing only one init in k-means instead of n_init=%d'</span></span><br><span class="line">                % n_init, RuntimeWarning, stacklevel=<span class="number">2</span>)</span><br><span class="line">            n_init = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># subtract of mean of x for more accurate distance computations</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> sp.issparse(X):</span><br><span class="line">        X_mean = X.mean(axis=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># The copy was already done above</span></span><br><span class="line">        X -= X_mean</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> hasattr(init, <span class="string">'__array__'</span>):</span><br><span class="line">            init -= X_mean</span><br><span class="line"></span><br><span class="line">    <span class="comment"># precompute squared norms of data points</span></span><br><span class="line">    x_squared_norms = row_norms(X, squared=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    best_labels, best_inertia, best_centers = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> n_clusters == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># elkan doesn't make sense for a single cluster, full will produce</span></span><br><span class="line">        <span class="comment"># the right result.</span></span><br><span class="line">        algorithm = <span class="string">"full"</span></span><br><span class="line">    <span class="keyword">if</span> algorithm == <span class="string">"auto"</span>:</span><br><span class="line">        algorithm = <span class="string">"full"</span> <span class="keyword">if</span> sp.issparse(X) <span class="keyword">else</span> <span class="string">'elkan'</span></span><br><span class="line">    <span class="keyword">if</span> algorithm == <span class="string">"full"</span>:</span><br><span class="line">        kmeans_single = _kmeans_single_lloyd</span><br><span class="line">    <span class="keyword">elif</span> algorithm == <span class="string">"elkan"</span>:</span><br><span class="line">        kmeans_single = _kmeans_single_elkan</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"Algorithm must be 'auto', 'full' or 'elkan', got"</span></span><br><span class="line">                         <span class="string">" %s"</span> % str(algorithm))</span><br><span class="line">    <span class="keyword">if</span> n_jobs == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># For a single thread, less memory is needed if we just store one set</span></span><br><span class="line">        <span class="comment"># of the best results (as opposed to one set per run per thread).</span></span><br><span class="line">        <span class="keyword">for</span> it <span class="keyword">in</span> range(n_init):</span><br><span class="line">            <span class="comment"># run a k-means once</span></span><br><span class="line">            <span class="comment"># 可选：kmeans_single_lloyd or kmeans_single_elkan</span></span><br><span class="line">            labels, inertia, centers, n_iter_ = kmeans_single(</span><br><span class="line">                X, sample_weight, n_clusters, max_iter=max_iter, init=init,</span><br><span class="line">                verbose=verbose, precompute_distances=precompute_distances,</span><br><span class="line">                tol=tol, x_squared_norms=x_squared_norms,</span><br><span class="line">                random_state=random_state)</span><br><span class="line">            <span class="comment"># determine if these results are the best so far</span></span><br><span class="line">            <span class="keyword">if</span> best_inertia <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> inertia &lt; best_inertia:</span><br><span class="line">                best_labels = labels.copy()</span><br><span class="line">                best_centers = centers.copy()</span><br><span class="line">                best_inertia = inertia</span><br><span class="line">                best_n_iter = n_iter_</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># parallelisation of k-means runs</span></span><br><span class="line">        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)</span><br><span class="line">        results = Parallel(n_jobs=n_jobs, verbose=<span class="number">0</span>)(</span><br><span class="line">            delayed(kmeans_single)(X, sample_weight, n_clusters,</span><br><span class="line">                                   max_iter=max_iter, init=init,</span><br><span class="line">                                   verbose=verbose, tol=tol,</span><br><span class="line">                                   precompute_distances=precompute_distances,</span><br><span class="line">                                   x_squared_norms=x_squared_norms,</span><br><span class="line">                                   <span class="comment"># Change seed to ensure variety</span></span><br><span class="line">                                   random_state=seed)</span><br><span class="line">            <span class="keyword">for</span> seed <span class="keyword">in</span> seeds)</span><br><span class="line">        <span class="comment"># Get results with the lowest inertia</span></span><br><span class="line">        labels, inertia, centers, n_iters = zip(*results)</span><br><span class="line">        best = np.argmin(inertia)</span><br><span class="line">        best_labels = labels[best]</span><br><span class="line">        best_inertia = inertia[best]</span><br><span class="line">        best_centers = centers[best]</span><br><span class="line">        best_n_iter = n_iters[best]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> sp.issparse(X):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> copy_x:</span><br><span class="line">            X += X_mean</span><br><span class="line">        best_centers += X_mean</span><br><span class="line"></span><br><span class="line">    distinct_clusters = len(set(best_labels))</span><br><span class="line">    <span class="keyword">if</span> distinct_clusters &lt; n_clusters:</span><br><span class="line">        warnings.warn(<span class="string">"Number of distinct clusters (&#123;&#125;) found smaller than "</span></span><br><span class="line">                      <span class="string">"n_clusters (&#123;&#125;). Possibly due to duplicate points "</span></span><br><span class="line">                      <span class="string">"in X."</span>.format(distinct_clusters, n_clusters),</span><br><span class="line">                      ConvergenceWarning, stacklevel=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> return_n_iter:</span><br><span class="line">        <span class="keyword">return</span> best_centers, best_labels, best_inertia, best_n_iter</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> best_centers, best_labels, best_inertia</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>_kmeans_single_lloyd</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_kmeans_single_lloyd</span><span class="params">(X, sample_weight, n_clusters, max_iter=<span class="number">300</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                         init=<span class="string">'k-means++'</span>, verbose=False, x_squared_norms=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                         random_state=None, tol=<span class="number">1e-4</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                         precompute_distances=True)</span>:</span></span><br><span class="line">    <span class="string">"""A single run of k-means, assumes preparation completed prior.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    X : array-like of floats, shape (n_samples, n_features)</span></span><br><span class="line"><span class="string">        The observations to cluster.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_clusters : int</span></span><br><span class="line"><span class="string">        The number of clusters to form as well as the number of</span></span><br><span class="line"><span class="string">        centroids to generate.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    sample_weight : array-like, shape (n_samples,)</span></span><br><span class="line"><span class="string">        The weights for each observation in X.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    max_iter : int, optional, default 300</span></span><br><span class="line"><span class="string">        Maximum number of iterations of the k-means algorithm to run.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    init : &#123;'k-means++', 'random', or ndarray, or a callable&#125;, optional</span></span><br><span class="line"><span class="string">        Method for initialization, default to 'k-means++':</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        'k-means++' : selects initial cluster centers for k-mean</span></span><br><span class="line"><span class="string">        clustering in a smart way to speed up convergence. See section</span></span><br><span class="line"><span class="string">        Notes in k_init for more details.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        'random': choose k observations (rows) at random from data for</span></span><br><span class="line"><span class="string">        the initial centroids.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        If an ndarray is passed, it should be of shape (k, p) and gives</span></span><br><span class="line"><span class="string">        the initial centers.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        If a callable is passed, it should take arguments X, k and</span></span><br><span class="line"><span class="string">        and a random state and return an initialization.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    tol : float, optional</span></span><br><span class="line"><span class="string">        The relative increment in the results before declaring convergence.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    verbose : boolean, optional</span></span><br><span class="line"><span class="string">        Verbosity mode</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    x_squared_norms : array</span></span><br><span class="line"><span class="string">        Precomputed x_squared_norms.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    precompute_distances : boolean, default: True</span></span><br><span class="line"><span class="string">        Precompute distances (faster but takes more memory).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    random_state : int, RandomState instance or None (default)</span></span><br><span class="line"><span class="string">        Determines random number generation for centroid initialization. Use</span></span><br><span class="line"><span class="string">        an int to make the randomness deterministic.</span></span><br><span class="line"><span class="string">        See :term:`Glossary &lt;random_state&gt;`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    centroid : float ndarray with shape (k, n_features)</span></span><br><span class="line"><span class="string">        Centroids found at the last iteration of k-means.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    label : integer ndarray with shape (n_samples,)</span></span><br><span class="line"><span class="string">        label[i] is the code or index of the centroid the</span></span><br><span class="line"><span class="string">        i'th observation is closest to.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    inertia : float</span></span><br><span class="line"><span class="string">        The final value of the inertia criterion (sum of squared distances to</span></span><br><span class="line"><span class="string">        the closest centroid for all observations in the training set).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_iter : int</span></span><br><span class="line"><span class="string">        Number of iterations run.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    random_state = check_random_state(random_state)</span><br><span class="line"></span><br><span class="line">    sample_weight = _check_sample_weight(X, sample_weight)</span><br><span class="line"></span><br><span class="line">    best_labels, best_inertia, best_centers = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="comment"># init</span></span><br><span class="line">    centers = _init_centroids(X, n_clusters, init, random_state=random_state,</span><br><span class="line">                              x_squared_norms=x_squared_norms)</span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        print(<span class="string">"Initialization complete"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Allocate memory to store the distances for each sample to its</span></span><br><span class="line">    <span class="comment"># closer center for reallocation in case of ties</span></span><br><span class="line">    distances = np.zeros(shape=(X.shape[<span class="number">0</span>],), dtype=X.dtype)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterations</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_iter):</span><br><span class="line">        centers_old = centers.copy()</span><br><span class="line">        <span class="comment"># labels assignment is also called the E-step of EM</span></span><br><span class="line">        labels, inertia = \</span><br><span class="line">            _labels_inertia(X, sample_weight, x_squared_norms, centers,</span><br><span class="line">                            precompute_distances=precompute_distances,</span><br><span class="line">                            distances=distances)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># computation of the means is also called the M-step of EM</span></span><br><span class="line">        <span class="keyword">if</span> sp.issparse(X):</span><br><span class="line">            centers = _k_means._centers_sparse(X, sample_weight, labels,</span><br><span class="line">                                               n_clusters, distances)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            centers = _k_means._centers_dense(X, sample_weight, labels,</span><br><span class="line">                                              n_clusters, distances)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            print(<span class="string">"Iteration %2d, inertia %.3f"</span> % (i, inertia))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> best_inertia <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> inertia &lt; best_inertia:</span><br><span class="line">            best_labels = labels.copy()</span><br><span class="line">            best_centers = centers.copy()</span><br><span class="line">            best_inertia = inertia</span><br><span class="line"></span><br><span class="line">        center_shift_total = squared_norm(centers_old - centers)</span><br><span class="line">        <span class="keyword">if</span> center_shift_total &lt;= tol:</span><br><span class="line">            <span class="keyword">if</span> verbose:</span><br><span class="line">                print(<span class="string">"Converged at iteration %d: "</span></span><br><span class="line">                      <span class="string">"center shift %e within tolerance %e"</span></span><br><span class="line">                      % (i, center_shift_total, tol))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> center_shift_total &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># rerun E-step in case of non-convergence so that predicted labels</span></span><br><span class="line">        <span class="comment"># match cluster centers</span></span><br><span class="line">        best_labels, best_inertia = \</span><br><span class="line">            _labels_inertia(X, sample_weight, x_squared_norms, best_centers,</span><br><span class="line">                            precompute_distances=precompute_distances,</span><br><span class="line">                            distances=distances)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> best_labels, best_inertia, best_centers, i + <span class="number">1</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>_kmeans_single_elkan</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_kmeans_single_elkan</span><span class="params">(X, sample_weight, n_clusters, max_iter=<span class="number">300</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                         init=<span class="string">'k-means++'</span>, verbose=False, x_squared_norms=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                         random_state=None, tol=<span class="number">1e-4</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                         precompute_distances=True)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> sp.issparse(X):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">"algorithm='elkan' not supported for sparse input X"</span>)</span><br><span class="line">    random_state = check_random_state(random_state)</span><br><span class="line">    <span class="keyword">if</span> x_squared_norms <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        x_squared_norms = row_norms(X, squared=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># init</span></span><br><span class="line">    centers = _init_centroids(X, n_clusters, init, random_state=random_state,</span><br><span class="line">                              x_squared_norms=x_squared_norms)</span><br><span class="line">    centers = np.ascontiguousarray(centers)</span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        print(<span class="string">'Initialization complete'</span>)</span><br><span class="line"></span><br><span class="line">    checked_sample_weight = _check_sample_weight(X, sample_weight)</span><br><span class="line">    centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,</span><br><span class="line">                                            n_clusters, centers, tol=tol,</span><br><span class="line">                                            max_iter=max_iter, verbose=verbose)</span><br><span class="line">    <span class="keyword">if</span> sample_weight <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        inertia = np.sum((X - centers[labels]) ** <span class="number">2</span>, dtype=np.float64)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        sq_distances = np.sum((X - centers[labels]) ** <span class="number">2</span>, axis=<span class="number">1</span>,</span><br><span class="line">                              dtype=np.float64) * checked_sample_weight</span><br><span class="line">        inertia = np.sum(sq_distances, dtype=np.float64)</span><br><span class="line">    <span class="keyword">return</span> labels, inertia, centers, n_iter</span><br></pre></td></tr></table></figure>
<h3 id="2-K-Modes"><a href="#2-K-Modes" class="headerlink" title="2. K-Modes"></a>2. K-Modes</h3><ul>
<li><p><strong>Algorithm</strong></p>
<ul>
<li>step1：随机确定k个聚类中心$C_1$, $C_2$ … $C_k$，$C_i$是长度为M的向量，$C_i$ = [$C_{1i}$,  $C_{2i}$,  … ,  $C_{mi}$]</li>
<li><p>step2：对于样本$x_j$ (j=1,2,…,N)，分别比较其与k个中心之间的距离</p>
<pre><code>   这里的**距离为不同属性值的个数**，假如$x_1$=[1, 2, 1, 3], $C_1$=[1, 2, 3, 4]，那么x1与C1之间的距离为2
</code></pre></li>
<li>step3：将$x_j$划分到距离最小的簇，在全部的样本都被划分完毕之后，重新确定簇中心，向量$C_i$中的每一个分量都更新为簇i中的众数</li>
<li>step4：重复步骤二和三，直到总距离（各个簇中样本与各自簇中心距离之和）不再降低，返回最后的聚类结果</li>
</ul>
</li>
</ul>
<ul>
<li><strong>KModes</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KModes</span><span class="params">(BaseEstimator, ClusterMixin)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""k-modes clustering algorithm for categorical data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    -----------</span></span><br><span class="line"><span class="string">    n_clusters : int, optional, default: 8</span></span><br><span class="line"><span class="string">        The number of clusters to form as well as the number of</span></span><br><span class="line"><span class="string">        centroids to generate.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    max_iter : int, default: 300</span></span><br><span class="line"><span class="string">        Maximum number of iterations of the k-modes algorithm for a</span></span><br><span class="line"><span class="string">        single run.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    cat_dissim : func, default: matching_dissim</span></span><br><span class="line"><span class="string">        Dissimilarity function used by the k-modes algorithm for categorical variables.</span></span><br><span class="line"><span class="string">        Defaults to the matching dissimilarity function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    init : &#123;'Huang', 'Cao', 'random' or an ndarray&#125;, default: 'Cao'</span></span><br><span class="line"><span class="string">        Method for initialization:</span></span><br><span class="line"><span class="string">        'Huang': Method in Huang [1997, 1998]</span></span><br><span class="line"><span class="string">        'Cao': Method in Cao et al. [2009]</span></span><br><span class="line"><span class="string">        'random': choose 'n_clusters' observations (rows) at random from</span></span><br><span class="line"><span class="string">        data for the initial centroids.</span></span><br><span class="line"><span class="string">        If an ndarray is passed, it should be of shape (n_clusters, n_features)</span></span><br><span class="line"><span class="string">        and gives the initial centroids.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_init : int, default: 10</span></span><br><span class="line"><span class="string">        Number of time the k-modes algorithm will be run with different</span></span><br><span class="line"><span class="string">        centroid seeds. The final results will be the best output of</span></span><br><span class="line"><span class="string">        n_init consecutive runs in terms of cost.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    verbose : int, optional</span></span><br><span class="line"><span class="string">        Verbosity mode.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    random_state : int, RandomState instance or None, optional, default: None</span></span><br><span class="line"><span class="string">        If int, random_state is the seed used by the random number generator;</span></span><br><span class="line"><span class="string">        If RandomState instance, random_state is the random number generator;</span></span><br><span class="line"><span class="string">        If None, the random number generator is the RandomState instance used</span></span><br><span class="line"><span class="string">        by `np.random`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_jobs : int, default: 1</span></span><br><span class="line"><span class="string">        The number of jobs to use for the computation. This works by computing</span></span><br><span class="line"><span class="string">        each of the n_init runs in parallel.</span></span><br><span class="line"><span class="string">        If -1 all CPUs are used. If 1 is given, no parallel computing code is</span></span><br><span class="line"><span class="string">        used at all, which is useful for debugging. For n_jobs below -1,</span></span><br><span class="line"><span class="string">        (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one</span></span><br><span class="line"><span class="string">        are used.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    cluster_centroids_ : array, [n_clusters, n_features]</span></span><br><span class="line"><span class="string">        Categories of cluster centroids</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    labels_ :</span></span><br><span class="line"><span class="string">        Labels of each point</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    cost_ : float</span></span><br><span class="line"><span class="string">        Clustering cost, defined as the sum distance of all points to</span></span><br><span class="line"><span class="string">        their respective cluster centroids.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_iter_ : int</span></span><br><span class="line"><span class="string">        The number of iterations the algorithm ran for.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Notes</span></span><br><span class="line"><span class="string">    -----</span></span><br><span class="line"><span class="string">    See:</span></span><br><span class="line"><span class="string">    Huang, Z.: Extensions to the k-modes algorithm for clustering large</span></span><br><span class="line"><span class="string">    data sets with categorical values, Data Mining and Knowledge</span></span><br><span class="line"><span class="string">    Discovery 2(3), 1998.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_clusters=<span class="number">8</span>, max_iter=<span class="number">100</span>, cat_dissim=matching_dissim,</span></span></span><br><span class="line"><span class="function"><span class="params">                 init=<span class="string">'Cao'</span>, n_init=<span class="number">1</span>, verbose=<span class="number">0</span>, random_state=None, n_jobs=<span class="number">1</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.n_clusters = n_clusters      <span class="comment"># 簇的个数</span></span><br><span class="line">        self.max_iter = max_iter          <span class="comment"># </span></span><br><span class="line">        self.cat_dissim = cat_dissim      <span class="comment"># 类别间距离的计算方法</span></span><br><span class="line">        self.init = init                  <span class="comment"># 初始中心点的选取方法 &#123;'Huang', 'Cao', 'random' </span></span><br><span class="line">                                          <span class="comment"># or an ndarray&#125;</span></span><br><span class="line">        self.n_init = n_init              <span class="comment"># 运行次数取最佳值</span></span><br><span class="line">        self.verbose = verbose            <span class="comment"># </span></span><br><span class="line">        self.random_state = random_state  <span class="comment">#</span></span><br><span class="line">        self.n_jobs = n_jobs              <span class="comment"># </span></span><br><span class="line">        <span class="keyword">if</span> ((isinstance(self.init, str) <span class="keyword">and</span> self.init == <span class="string">'Cao'</span>) <span class="keyword">or</span></span><br><span class="line">                hasattr(self.init, <span class="string">'__array__'</span>)) <span class="keyword">and</span> self.n_init &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> self.verbose:</span><br><span class="line">                print(<span class="string">"Initialization method and algorithm are deterministic. "</span></span><br><span class="line">                      <span class="string">"Setting n_init to 1."</span>)</span><br><span class="line">            self.n_init = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None, **kwargs)</span>:</span></span><br><span class="line">        <span class="string">"""Compute k-modes clustering.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : array-like, shape=[n_samples, n_features]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        random_state = check_random_state(self.random_state)</span><br><span class="line">        self._enc_cluster_centroids, self._enc_map, self.labels_,\</span><br><span class="line">            self.cost_, self.n_iter_ = k_modes(X,</span><br><span class="line">                                               self.n_clusters,</span><br><span class="line">                                               self.max_iter,</span><br><span class="line">                                               self.cat_dissim,</span><br><span class="line">                                               self.init,</span><br><span class="line">                                               self.n_init,</span><br><span class="line">                                               self.verbose,</span><br><span class="line">                                               random_state,</span><br><span class="line">                                               self.n_jobs)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit_predict</span><span class="params">(self, X, y=None, **kwargs)</span>:</span></span><br><span class="line">        <span class="string">"""Compute cluster centroids and predict cluster index for each sample.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Convenience method; equivalent to calling fit(X) followed by</span></span><br><span class="line"><span class="string">        predict(X).</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> self.fit(X, **kwargs).predict(X, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X, **kwargs)</span>:</span></span><br><span class="line">        <span class="string">"""Predict the closest cluster each sample in X belongs to.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : array-like, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            New data to predict.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        labels : array, shape [n_samples,]</span></span><br><span class="line"><span class="string">            Index of the cluster each sample belongs to.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">assert</span> hasattr(self, <span class="string">'_enc_cluster_centroids'</span>), <span class="string">"Model not yet fitted."</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.verbose <span class="keyword">and</span> self.cat_dissim == ng_dissim:</span><br><span class="line">            print(<span class="string">"Ng's dissimilarity measure was used to train this model, "</span></span><br><span class="line">                  <span class="string">"but now that it is predicting the model will fall back to "</span></span><br><span class="line">                  <span class="string">"using simple matching dissimilarity."</span>)</span><br><span class="line"></span><br><span class="line">        X = check_array(X, dtype=<span class="literal">None</span>)</span><br><span class="line">        X, _ = encode_features(X, enc_map=self._enc_map)</span><br><span class="line">        <span class="keyword">return</span> _labels_cost(X, self._enc_cluster_centroids, self.cat_dissim)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cluster_centroids_</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'_enc_cluster_centroids'</span>):</span><br><span class="line">            <span class="keyword">return</span> decode_centroids(self._enc_cluster_centroids, self._enc_map)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> AttributeError(<span class="string">"'&#123;&#125;' object has no attribute 'cluster_centroids_' "</span></span><br><span class="line">                                 <span class="string">"because the model is not yet fitted."</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>k_modes</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_modes</span><span class="params">(X, n_clusters, max_iter, dissim, init, n_init, verbose, random_state, n_jobs)</span>:</span></span><br><span class="line">    <span class="string">"""k-modes algorithm"""</span></span><br><span class="line">    random_state = check_random_state(random_state)</span><br><span class="line">    <span class="keyword">if</span> sparse.issparse(X):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">"k-modes does not support sparse data."</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert pandas objects to numpy arrays.</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'pandas'</span> <span class="keyword">in</span> str(X.__class__):</span><br><span class="line">        X = X.values</span><br><span class="line"></span><br><span class="line">    X = check_array(X, dtype=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert the categorical values in X to integers for speed.</span></span><br><span class="line">    <span class="comment"># Based on the unique values in X, we can make a mapping to achieve this.</span></span><br><span class="line">    X, enc_map = encode_features(X)</span><br><span class="line"></span><br><span class="line">    n_points, n_attrs = X.shape</span><br><span class="line">    <span class="keyword">assert</span> n_clusters &lt;= n_points, <span class="string">"Cannot have more clusters (&#123;&#125;) "</span> \</span><br><span class="line">                                   <span class="string">"than data points (&#123;&#125;)."</span>.format(n_clusters, n_points)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Are there more n_clusters than unique rows? Then set the unique</span></span><br><span class="line">    <span class="comment"># rows as initial values and skip iteration.</span></span><br><span class="line">    unique = get_unique_rows(X)</span><br><span class="line">    n_unique = unique.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> n_unique &lt;= n_clusters:</span><br><span class="line">        max_iter = <span class="number">0</span></span><br><span class="line">        n_init = <span class="number">1</span></span><br><span class="line">        n_clusters = n_unique</span><br><span class="line">        init = unique</span><br><span class="line"></span><br><span class="line">    results = []</span><br><span class="line">    seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)</span><br><span class="line">    <span class="keyword">if</span> n_jobs == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> init_no <span class="keyword">in</span> range(n_init):</span><br><span class="line">            results.append(k_modes_single(X, n_clusters, n_points, n_attrs, max_iter,</span><br><span class="line">                                          dissim, init, init_no, verbose, seeds[init_no]))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        results = Parallel(n_jobs=n_jobs, verbose=<span class="number">0</span>)(</span><br><span class="line">            delayed(k_modes_single)(X, n_clusters, n_points, n_attrs, max_iter,</span><br><span class="line">                                    dissim, init, init_no, verbose, seed)</span><br><span class="line">            <span class="keyword">for</span> init_no, seed <span class="keyword">in</span> enumerate(seeds))</span><br><span class="line">    all_centroids, all_labels, all_costs, all_n_iters = zip(*results)</span><br><span class="line"></span><br><span class="line">    best = np.argmin(all_costs)</span><br><span class="line">    <span class="keyword">if</span> n_init &gt; <span class="number">1</span> <span class="keyword">and</span> verbose:</span><br><span class="line">        print(<span class="string">"Best run was number &#123;&#125;"</span>.format(best + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> all_centroids[best], enc_map, all_labels[best], \</span><br><span class="line">        all_costs[best], all_n_iters[best]</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>k_modes_single</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_modes_single</span><span class="params">(X, n_clusters, n_points, n_attrs, max_iter, dissim, init, init_no,</span></span></span><br><span class="line"><span class="function"><span class="params">                   verbose, random_state)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    X            : </span></span><br><span class="line"><span class="string">    n_clusters   : </span></span><br><span class="line"><span class="string">    n_points     : n_points, n_attrs = X.shape</span></span><br><span class="line"><span class="string">    n_attrs      :</span></span><br><span class="line"><span class="string">    max_iter     : Maximum number of iterations of the k-modes algorithm for a single run.</span></span><br><span class="line"><span class="string">    dissim       : func, default: matching_dissim, &#123;matching_dissim, ng_dissim&#125;</span></span><br><span class="line"><span class="string">        Dissimilarity function used by the k-modes algorithm for categorical variables.</span></span><br><span class="line"><span class="string">        Defaults to the matching dissimilarity function. </span></span><br><span class="line"><span class="string">    init         :</span></span><br><span class="line"><span class="string">    inti_no      :</span></span><br><span class="line"><span class="string">    verbose      :</span></span><br><span class="line"><span class="string">    random_state :</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    random_state = check_random_state(random_state)</span><br><span class="line">    <span class="comment"># _____ INIT _____</span></span><br><span class="line">    <span class="comment"># 初始化，选取中心点</span></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        print(<span class="string">"Init: initializing centroids"</span>)</span><br><span class="line">    <span class="comment"># 1. method huang</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(init, str) <span class="keyword">and</span> init.lower() == <span class="string">'huang'</span>:</span><br><span class="line">        centroids = init_huang(X, n_clusters, dissim, random_state)</span><br><span class="line">    <span class="comment"># 2. method cao</span></span><br><span class="line">    <span class="keyword">elif</span> isinstance(init, str) <span class="keyword">and</span> init.lower() == <span class="string">'cao'</span>:</span><br><span class="line">        centroids = init_cao(X, n_clusters, dissim)</span><br><span class="line">    <span class="comment"># 3. 随机选取</span></span><br><span class="line">    <span class="keyword">elif</span> isinstance(init, str) <span class="keyword">and</span> init.lower() == <span class="string">'random'</span>:</span><br><span class="line">        seeds = random_state.choice(range(n_points), n_clusters)</span><br><span class="line">        centroids = X[seeds]</span><br><span class="line">    <span class="comment"># 4. 使用提供好的array</span></span><br><span class="line">    <span class="keyword">elif</span> hasattr(init, <span class="string">'__array__'</span>):</span><br><span class="line">        <span class="comment"># Make sure init is a 2D array.</span></span><br><span class="line">        <span class="keyword">if</span> len(init.shape) == <span class="number">1</span>:</span><br><span class="line">            init = np.atleast_2d(init).T</span><br><span class="line">        <span class="keyword">assert</span> init.shape[<span class="number">0</span>] == n_clusters, \</span><br><span class="line">            <span class="string">"Wrong number of initial centroids in init (&#123;&#125;, should be &#123;&#125;)."</span> \</span><br><span class="line">                .format(init.shape[<span class="number">0</span>], n_clusters)</span><br><span class="line">        <span class="keyword">assert</span> init.shape[<span class="number">1</span>] == n_attrs, \</span><br><span class="line">            <span class="string">"Wrong number of attributes in init (&#123;&#125;, should be &#123;&#125;)."</span> \</span><br><span class="line">                .format(init.shape[<span class="number">1</span>], n_attrs)</span><br><span class="line">        centroids = np.asarray(init, dtype=np.uint16)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        print(<span class="string">"Init: initializing clusters"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># rows : n_clusters, cols : n_points</span></span><br><span class="line">    membship = np.zeros((n_clusters, n_points), dtype=np.uint8)</span><br><span class="line">    <span class="comment"># cl_attr_freq is a list of lists with dictionaries that contain the</span></span><br><span class="line">    <span class="comment"># frequencies of values per cluster and attribute.</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># rows : n_clusters, cols : n_attrs</span></span><br><span class="line">    cl_attr_freq = [[defaultdict(int) <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_attrs)]</span><br><span class="line">                    <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_clusters)]</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> ipoint, curpoint <span class="keyword">in</span> enumerate(X):</span><br><span class="line">        <span class="comment"># Initial assignment to clusters</span></span><br><span class="line">        <span class="comment"># 返回距离最近的中心点</span></span><br><span class="line">        clust = np.argmin(dissim(centroids, curpoint, X=X, membship=membship))</span><br><span class="line">        membship[clust, ipoint] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Count attribute values per cluster.</span></span><br><span class="line">        <span class="keyword">for</span> iattr, curattr <span class="keyword">in</span> enumerate(curpoint):</span><br><span class="line">            cl_attr_freq[clust][iattr][curattr] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Perform an initial centroid update.</span></span><br><span class="line">    <span class="keyword">for</span> ik <span class="keyword">in</span> range(n_clusters):</span><br><span class="line">        <span class="keyword">for</span> iattr <span class="keyword">in</span> range(n_attrs):</span><br><span class="line">            <span class="keyword">if</span> sum(membship[ik]) == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># Empty centroid, choose randomly</span></span><br><span class="line">                centroids[ik, iattr] = random_state.choice(X[:, iattr])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                centroids[ik, iattr] = get_max_value_key(cl_attr_freq[ik][iattr])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># _____ ITERATION _____</span></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        print(<span class="string">"Starting iterations..."</span>)</span><br><span class="line">    itr = <span class="number">0</span></span><br><span class="line">    labels = <span class="literal">None</span></span><br><span class="line">    converged = <span class="literal">False</span></span><br><span class="line">    cost = np.Inf</span><br><span class="line">    <span class="keyword">while</span> itr &lt;= max_iter <span class="keyword">and</span> <span class="keyword">not</span> converged:</span><br><span class="line">        itr += <span class="number">1</span></span><br><span class="line">        centroids, moves = _k_modes_iter(X, centroids, cl_attr_freq, membship, dissim, random_state)</span><br><span class="line">        <span class="comment"># All points seen in this iteration</span></span><br><span class="line">        labels, ncost = _labels_cost(X, centroids, dissim, membship)</span><br><span class="line">        converged = (moves == <span class="number">0</span>) <span class="keyword">or</span> (ncost &gt;= cost)</span><br><span class="line">        cost = ncost</span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            print(<span class="string">"Run &#123;&#125;, iteration: &#123;&#125;/&#123;&#125;, moves: &#123;&#125;, cost: &#123;&#125;"</span></span><br><span class="line">                  .format(init_no + <span class="number">1</span>, itr, max_iter, moves, cost))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> centroids, labels, cost, itr</span><br></pre></td></tr></table></figure>
<h3 id="3-K-prototype"><a href="#3-K-prototype" class="headerlink" title="3. K-prototype"></a>3. K-prototype</h3><ul>
<li><strong>Algorithm</strong></li>
<li><strong>KPrototypes</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KPrototypes</span><span class="params">(kmodes.KModes)</span>:</span></span><br><span class="line">    <span class="string">"""k-protoypes clustering algorithm for mixed numerical/categorical data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    -----------</span></span><br><span class="line"><span class="string">    n_clusters : int, optional, default: 8</span></span><br><span class="line"><span class="string">        The number of clusters to form as well as the number of</span></span><br><span class="line"><span class="string">        centroids to generate.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    max_iter : int, default: 300</span></span><br><span class="line"><span class="string">        Maximum number of iterations of the k-modes algorithm for a</span></span><br><span class="line"><span class="string">        single run.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    num_dissim : func, default: euclidian_dissim</span></span><br><span class="line"><span class="string">        Dissimilarity function used by the algorithm for numerical variables.</span></span><br><span class="line"><span class="string">        Defaults to the Euclidian dissimilarity function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    cat_dissim : func, default: matching_dissim</span></span><br><span class="line"><span class="string">        Dissimilarity function used by the kmodes algorithm for categorical variables.</span></span><br><span class="line"><span class="string">        Defaults to the matching dissimilarity function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_init : int, default: 10</span></span><br><span class="line"><span class="string">        Number of time the k-modes algorithm will be run with different</span></span><br><span class="line"><span class="string">        centroid seeds. The final results will be the best output of</span></span><br><span class="line"><span class="string">        n_init consecutive runs in terms of cost.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    init : &#123;'Huang', 'Cao', 'random' or a list of ndarrays&#125;, default: 'Cao'</span></span><br><span class="line"><span class="string">        Method for initialization:</span></span><br><span class="line"><span class="string">        'Huang': Method in Huang [1997, 1998]</span></span><br><span class="line"><span class="string">        'Cao': Method in Cao et al. [2009]</span></span><br><span class="line"><span class="string">        'random': choose 'n_clusters' observations (rows) at random from</span></span><br><span class="line"><span class="string">        data for the initial centroids.</span></span><br><span class="line"><span class="string">        If a list of ndarrays is passed, it should be of length 2, with</span></span><br><span class="line"><span class="string">        shapes (n_clusters, n_features) for numerical and categorical</span></span><br><span class="line"><span class="string">        data respectively. These are the initial centroids.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    gamma : float, default: None</span></span><br><span class="line"><span class="string">        Weighing factor that determines relative importance of numerical vs.</span></span><br><span class="line"><span class="string">        categorical attributes (see discussion in Huang [1997]). By default,</span></span><br><span class="line"><span class="string">        automatically calculated from data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    verbose : integer, optional</span></span><br><span class="line"><span class="string">        Verbosity mode.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    random_state : int, RandomState instance or None, optional, default: None</span></span><br><span class="line"><span class="string">        If int, random_state is the seed used by the random number generator;</span></span><br><span class="line"><span class="string">        If RandomState instance, random_state is the random number generator;</span></span><br><span class="line"><span class="string">        If None, the random number generator is the RandomState instance used</span></span><br><span class="line"><span class="string">        by `np.random`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_jobs : int, default: 1</span></span><br><span class="line"><span class="string">        The number of jobs to use for the computation. This works by computing</span></span><br><span class="line"><span class="string">        each of the n_init runs in parallel.</span></span><br><span class="line"><span class="string">        If -1 all CPUs are used. If 1 is given, no parallel computing code is</span></span><br><span class="line"><span class="string">        used at all, which is useful for debugging. For n_jobs below -1,</span></span><br><span class="line"><span class="string">        (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one</span></span><br><span class="line"><span class="string">        are used.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    cluster_centroids_ : array, [n_clusters, n_features]</span></span><br><span class="line"><span class="string">        Categories of cluster centroids</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    labels_ :</span></span><br><span class="line"><span class="string">        Labels of each point</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    cost_ : float</span></span><br><span class="line"><span class="string">        Clustering cost, defined as the sum distance of all points to</span></span><br><span class="line"><span class="string">        their respective cluster centroids.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    n_iter_ : int</span></span><br><span class="line"><span class="string">        The number of iterations the algorithm ran for.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    gamma : float</span></span><br><span class="line"><span class="string">        The (potentially calculated) weighing factor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Notes</span></span><br><span class="line"><span class="string">    -----</span></span><br><span class="line"><span class="string">    See:</span></span><br><span class="line"><span class="string">    Huang, Z.: Extensions to the k-modes algorithm for clustering large</span></span><br><span class="line"><span class="string">    data sets with categorical values, Data Mining and Knowledge</span></span><br><span class="line"><span class="string">    Discovery 2(3), 1998.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_clusters=<span class="number">8</span>, max_iter=<span class="number">100</span>, num_dissim=euclidean_dissim,</span></span></span><br><span class="line"><span class="function"><span class="params">                 cat_dissim=matching_dissim, init=<span class="string">'Huang'</span>, n_init=<span class="number">10</span>, gamma=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 verbose=<span class="number">0</span>, random_state=None, n_jobs=<span class="number">1</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">        super(KPrototypes, self).__init__(n_clusters, max_iter, cat_dissim, init,</span><br><span class="line">                                          verbose=verbose, random_state=random_state,</span><br><span class="line">                                          n_jobs=n_jobs)</span><br><span class="line">        self.num_dissim = num_dissim</span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.n_init = n_init</span><br><span class="line">        <span class="keyword">if</span> isinstance(self.init, list) <span class="keyword">and</span> self.n_init &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> self.verbose:</span><br><span class="line">                print(<span class="string">"Initialization method is deterministic. "</span></span><br><span class="line">                      <span class="string">"Setting n_init to 1."</span>)</span><br><span class="line">            self.n_init = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None, categorical=None)</span>:</span></span><br><span class="line">        <span class="string">"""Compute k-prototypes clustering.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : array-like, shape=[n_samples, n_features]</span></span><br><span class="line"><span class="string">        categorical : Index of columns that contain categorical data</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        random_state = check_random_state(self.random_state)</span><br><span class="line">        <span class="comment"># If self.gamma is None, gamma will be automatically determined from</span></span><br><span class="line">        <span class="comment"># the data. The function below returns its value.</span></span><br><span class="line">        self._enc_cluster_centroids, self._enc_map, self.labels_, self.cost_,\</span><br><span class="line">            self.n_iter_, self.gamma = k_prototypes(X,</span><br><span class="line">                                                    categorical,</span><br><span class="line">                                                    self.n_clusters,</span><br><span class="line">                                                    self.max_iter,</span><br><span class="line">                                                    self.num_dissim,</span><br><span class="line">                                                    self.cat_dissim,</span><br><span class="line">                                                    self.gamma,</span><br><span class="line">                                                    self.init,</span><br><span class="line">                                                    self.n_init,</span><br><span class="line">                                                    self.verbose,</span><br><span class="line">                                                    random_state,</span><br><span class="line">                                                    self.n_jobs)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X, categorical=None)</span>:</span></span><br><span class="line">        <span class="string">"""Predict the closest cluster each sample in X belongs to.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        X : array-like, shape = [n_samples, n_features]</span></span><br><span class="line"><span class="string">            New data to predict.</span></span><br><span class="line"><span class="string">        categorical : Index of columns that contain categorical data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        labels : array, shape [n_samples,]</span></span><br><span class="line"><span class="string">            Index of the cluster each sample belongs to.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">assert</span> hasattr(self, <span class="string">'_enc_cluster_centroids'</span>), <span class="string">"Model not yet fitted."</span></span><br><span class="line"></span><br><span class="line">        Xnum, Xcat = _split_num_cat(X, categorical)</span><br><span class="line">        Xnum, Xcat = check_array(Xnum), check_array(Xcat, dtype=<span class="literal">None</span>)</span><br><span class="line">        Xcat, _ = encode_features(Xcat, enc_map=self._enc_map)</span><br><span class="line">        <span class="keyword">return</span> _labels_cost(Xnum, Xcat, self._enc_cluster_centroids,</span><br><span class="line">                            self.num_dissim, self.cat_dissim, self.gamma)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cluster_centroids_</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> hasattr(self, <span class="string">'_enc_cluster_centroids'</span>):</span><br><span class="line">            <span class="keyword">return</span> [</span><br><span class="line">                self._enc_cluster_centroids[<span class="number">0</span>],</span><br><span class="line">                decode_centroids(self._enc_cluster_centroids[<span class="number">1</span>], self._enc_map)</span><br><span class="line">            ]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> AttributeError(<span class="string">"'&#123;&#125;' object has no attribute 'cluster_centroids_' "</span></span><br><span class="line">                                 <span class="string">"because the model is not yet fitted."</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>k_prototypes</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_prototypes</span><span class="params">(X, categorical, n_clusters, max_iter, num_dissim, cat_dissim,</span></span></span><br><span class="line"><span class="function"><span class="params">                 gamma, init, n_init, verbose, random_state, n_jobs)</span>:</span></span><br><span class="line">    <span class="string">"""k-prototypes algorithm"""</span></span><br><span class="line">    random_state = check_random_state(random_state)</span><br><span class="line">    <span class="keyword">if</span> sparse.issparse(X):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">"k-prototypes does not support sparse data."</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert pandas objects to numpy arrays.</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'pandas'</span> <span class="keyword">in</span> str(X.__class__):</span><br><span class="line">        X = X.values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> categorical <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> <span class="keyword">not</span> categorical:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError(</span><br><span class="line">            <span class="string">"No categorical data selected, effectively doing k-means. "</span></span><br><span class="line">            <span class="string">"Present a list of categorical columns, or use scikit-learn's "</span></span><br><span class="line">            <span class="string">"KMeans instead."</span></span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">if</span> isinstance(categorical, int):</span><br><span class="line">        categorical = [categorical]</span><br><span class="line">    <span class="keyword">assert</span> len(categorical) != X.shape[<span class="number">1</span>], \</span><br><span class="line">        <span class="string">"All columns are categorical, use k-modes instead of k-prototypes."</span></span><br><span class="line">    <span class="keyword">assert</span> max(categorical) &lt; X.shape[<span class="number">1</span>], \</span><br><span class="line">        <span class="string">"Categorical index larger than number of columns."</span></span><br><span class="line"></span><br><span class="line">    ncatattrs = len(categorical)</span><br><span class="line">    nnumattrs = X.shape[<span class="number">1</span>] - ncatattrs</span><br><span class="line">    n_points = X.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">assert</span> n_clusters &lt;= n_points, <span class="string">"Cannot have more clusters (&#123;&#125;) "</span> \</span><br><span class="line">                                   <span class="string">"than data points (&#123;&#125;)."</span>.format(n_clusters, n_points)</span><br><span class="line"></span><br><span class="line">    Xnum, Xcat = _split_num_cat(X, categorical)</span><br><span class="line">    Xnum, Xcat = check_array(Xnum), check_array(Xcat, dtype=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert the categorical values in Xcat to integers for speed.</span></span><br><span class="line">    <span class="comment"># Based on the unique values in Xcat, we can make a mapping to achieve this.</span></span><br><span class="line">    Xcat, enc_map = encode_features(Xcat)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Are there more n_clusters than unique rows? Then set the unique</span></span><br><span class="line">    <span class="comment"># rows as initial values and skip iteration.</span></span><br><span class="line">    unique = get_unique_rows(X)</span><br><span class="line">    n_unique = unique.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> n_unique &lt;= n_clusters:</span><br><span class="line">        max_iter = <span class="number">0</span></span><br><span class="line">        n_init = <span class="number">1</span></span><br><span class="line">        n_clusters = n_unique</span><br><span class="line">        init = list(_split_num_cat(unique, categorical))</span><br><span class="line">        init[<span class="number">1</span>], _ = encode_features(init[<span class="number">1</span>], enc_map)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Estimate a good value for gamma, which determines the weighing of</span></span><br><span class="line">    <span class="comment"># categorical values in clusters (see Huang [1997]).</span></span><br><span class="line">    <span class="keyword">if</span> gamma <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        gamma = <span class="number">0.5</span> * Xnum.std()</span><br><span class="line"></span><br><span class="line">    results = []</span><br><span class="line">    seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)</span><br><span class="line">    <span class="keyword">if</span> n_jobs == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> init_no <span class="keyword">in</span> range(n_init):</span><br><span class="line">            results.append(k_prototypes_single(Xnum, Xcat, nnumattrs, ncatattrs,</span><br><span class="line">                                               n_clusters, n_points, max_iter,</span><br><span class="line">                                               num_dissim, cat_dissim, gamma,</span><br><span class="line">                                               init, init_no, verbose, seeds[init_no]))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        results = Parallel(n_jobs=n_jobs, verbose=<span class="number">0</span>)(</span><br><span class="line">            delayed(k_prototypes_single)(Xnum, Xcat, nnumattrs, ncatattrs,</span><br><span class="line">                                         n_clusters, n_points, max_iter,</span><br><span class="line">                                         num_dissim, cat_dissim, gamma,</span><br><span class="line">                                         init, init_no, verbose, seed)</span><br><span class="line">            <span class="keyword">for</span> init_no, seed <span class="keyword">in</span> enumerate(seeds))</span><br><span class="line">    all_centroids, all_labels, all_costs, all_n_iters = zip(*results)</span><br><span class="line"></span><br><span class="line">    best = np.argmin(all_costs)</span><br><span class="line">    <span class="keyword">if</span> n_init &gt; <span class="number">1</span> <span class="keyword">and</span> verbose:</span><br><span class="line">        print(<span class="string">"Best run was number &#123;&#125;"</span>.format(best + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Note: return gamma in case it was automatically determined.</span></span><br><span class="line">    <span class="keyword">return</span> all_centroids[best], enc_map, all_labels[best], \</span><br><span class="line">        all_costs[best], all_n_iters[best], gamma</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>k_prototypes_single</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_prototypes_single</span><span class="params">(Xnum, Xcat, nnumattrs, ncatattrs, n_clusters, n_points,</span></span></span><br><span class="line"><span class="function"><span class="params">                        max_iter, num_dissim, cat_dissim, gamma, init, init_no,</span></span></span><br><span class="line"><span class="function"><span class="params">                        verbose, random_state)</span>:</span></span><br><span class="line">    <span class="comment"># For numerical part of initialization, we don't have a guarantee</span></span><br><span class="line">    <span class="comment"># that there is not an empty cluster, so we need to retry until</span></span><br><span class="line">    <span class="comment"># there is none.</span></span><br><span class="line">    random_state = check_random_state(random_state)</span><br><span class="line">    init_tries = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化几个中心点</span></span><br><span class="line">    <span class="comment"># 可能存在失败的情况</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        init_tries += <span class="number">1</span></span><br><span class="line">        <span class="comment"># _____ INIT _____</span></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            print(<span class="string">"Init: initializing centroids"</span>)</span><br><span class="line">        <span class="keyword">if</span> isinstance(init, str) <span class="keyword">and</span> init.lower() == <span class="string">'huang'</span>:</span><br><span class="line">            centroids = kmodes.init_huang(Xcat, n_clusters, cat_dissim, random_state)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(init, str) <span class="keyword">and</span> init.lower() == <span class="string">'cao'</span>:</span><br><span class="line">            centroids = kmodes.init_cao(Xcat, n_clusters, cat_dissim)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(init, str) <span class="keyword">and</span> init.lower() == <span class="string">'random'</span>:</span><br><span class="line">            seeds = random_state.choice(range(n_points), n_clusters)</span><br><span class="line">            centroids = Xcat[seeds]</span><br><span class="line">        <span class="keyword">elif</span> isinstance(init, list):</span><br><span class="line">            <span class="comment"># Make sure inits are 2D arrays.</span></span><br><span class="line">            init = [np.atleast_2d(cur_init).T <span class="keyword">if</span> len(cur_init.shape) == <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span> cur_init</span><br><span class="line">                    <span class="keyword">for</span> cur_init <span class="keyword">in</span> init]</span><br><span class="line">            <span class="keyword">assert</span> init[<span class="number">0</span>].shape[<span class="number">0</span>] == n_clusters, \</span><br><span class="line">                <span class="string">"Wrong number of initial numerical centroids in init "</span> \</span><br><span class="line">                <span class="string">"(&#123;&#125;, should be &#123;&#125;)."</span>.format(init[<span class="number">0</span>].shape[<span class="number">0</span>], n_clusters)</span><br><span class="line">            <span class="keyword">assert</span> init[<span class="number">0</span>].shape[<span class="number">1</span>] == nnumattrs, \</span><br><span class="line">                <span class="string">"Wrong number of numerical attributes in init (&#123;&#125;, should be &#123;&#125;)."</span> \</span><br><span class="line">                    .format(init[<span class="number">0</span>].shape[<span class="number">1</span>], nnumattrs)</span><br><span class="line">            <span class="keyword">assert</span> init[<span class="number">1</span>].shape[<span class="number">0</span>] == n_clusters, \</span><br><span class="line">                <span class="string">"Wrong number of initial categorical centroids in init (&#123;&#125;, "</span> \</span><br><span class="line">                <span class="string">"should be &#123;&#125;)."</span>.format(init[<span class="number">1</span>].shape[<span class="number">0</span>], n_clusters)</span><br><span class="line">            <span class="keyword">assert</span> init[<span class="number">1</span>].shape[<span class="number">1</span>] == ncatattrs, \</span><br><span class="line">                <span class="string">"Wrong number of categorical attributes in init (&#123;&#125;, should be &#123;&#125;)."</span> \</span><br><span class="line">                    .format(init[<span class="number">1</span>].shape[<span class="number">1</span>], ncatattrs)</span><br><span class="line">            centroids = [np.asarray(init[<span class="number">0</span>], dtype=np.float64),</span><br><span class="line">                         np.asarray(init[<span class="number">1</span>], dtype=np.uint16)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">"Initialization method not supported."</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(init, list):</span><br><span class="line">            <span class="comment"># Numerical is initialized by drawing from normal distribution,</span></span><br><span class="line">            <span class="comment"># categorical following the k-modes methods.</span></span><br><span class="line">            meanx = np.mean(Xnum, axis=<span class="number">0</span>)</span><br><span class="line">            stdx = np.std(Xnum, axis=<span class="number">0</span>)</span><br><span class="line">            centroids = [</span><br><span class="line">                meanx + random_state.randn(n_clusters, nnumattrs) * stdx,</span><br><span class="line">                centroids</span><br><span class="line">            ]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            print(<span class="string">"Init: initializing clusters"</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 计算对应组内的成员</span></span><br><span class="line">        membship = np.zeros((n_clusters, n_points), dtype=np.uint8)</span><br><span class="line">        <span class="comment"># Keep track of the sum of attribute values per cluster so that we</span></span><br><span class="line">        <span class="comment"># can do k-means on the numerical attributes.</span></span><br><span class="line">        cl_attr_sum = np.zeros((n_clusters, nnumattrs), dtype=np.float64)</span><br><span class="line">        <span class="comment"># Same for the membership sum per cluster</span></span><br><span class="line">        cl_memb_sum = np.zeros(n_clusters, dtype=int)</span><br><span class="line">        <span class="comment"># cl_attr_freq is a list of lists with dictionaries that contain</span></span><br><span class="line">        <span class="comment"># the frequencies of values per cluster and attribute.</span></span><br><span class="line">        cl_attr_freq = [[defaultdict(int) <span class="keyword">for</span> _ <span class="keyword">in</span> range(ncatattrs)]</span><br><span class="line">                        <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_clusters)]</span><br><span class="line">        <span class="keyword">for</span> ipoint <span class="keyword">in</span> range(n_points):</span><br><span class="line">            <span class="comment"># Initial assignment to clusters</span></span><br><span class="line">            <span class="comment"># 计算初始的归属类，分别由类别的和数值型数据组成</span></span><br><span class="line">            <span class="comment"># gamma是类别特征的权重</span></span><br><span class="line">            clust = np.argmin(</span><br><span class="line">                num_dissim(centroids[<span class="number">0</span>], Xnum[ipoint]) + gamma *</span><br><span class="line">                cat_dissim(centroids[<span class="number">1</span>], Xcat[ipoint], X=Xcat, membship=membship)</span><br><span class="line">            )</span><br><span class="line">            membship[clust, ipoint] = <span class="number">1</span></span><br><span class="line">            cl_memb_sum[clust] += <span class="number">1</span></span><br><span class="line">            <span class="comment"># Count attribute values per cluster.</span></span><br><span class="line">            <span class="keyword">for</span> iattr, curattr <span class="keyword">in</span> enumerate(Xnum[ipoint]):</span><br><span class="line">                cl_attr_sum[clust, iattr] += curattr</span><br><span class="line">            <span class="keyword">for</span> iattr, curattr <span class="keyword">in</span> enumerate(Xcat[ipoint]):</span><br><span class="line">                cl_attr_freq[clust][iattr][curattr] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># If no empty clusters, then consider initialization finalized.</span></span><br><span class="line">        <span class="comment"># 如果每一组的成员个数都大于0的话，则算是初始化成功，否则需要重新初始化</span></span><br><span class="line">        <span class="keyword">if</span> membship.sum(axis=<span class="number">1</span>).min() &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> 如果不修改随机种子或者其他的数据，每次跑的结果都是一样的</span></span><br><span class="line">        <span class="keyword">if</span> init_tries == MAX_INIT_TRIES:</span><br><span class="line">            <span class="comment"># Could not get rid of empty clusters. Randomly</span></span><br><span class="line">            <span class="comment"># initialize instead.</span></span><br><span class="line">            init = <span class="string">'random'</span></span><br><span class="line">        <span class="keyword">elif</span> init_tries == RAISE_INIT_TRIES:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">"Clustering algorithm could not initialize. "</span></span><br><span class="line">                <span class="string">"Consider assigning the initial clusters manually."</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Perform an initial centroid update.</span></span><br><span class="line">    <span class="keyword">for</span> ik <span class="keyword">in</span> range(n_clusters):</span><br><span class="line">        <span class="keyword">for</span> iattr <span class="keyword">in</span> range(nnumattrs):</span><br><span class="line">            centroids[<span class="number">0</span>][ik, iattr] = cl_attr_sum[ik, iattr] / cl_memb_sum[ik]</span><br><span class="line">        <span class="keyword">for</span> iattr <span class="keyword">in</span> range(ncatattrs):</span><br><span class="line">            centroids[<span class="number">1</span>][ik, iattr] = get_max_value_key(cl_attr_freq[ik][iattr])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># _____ ITERATION _____</span></span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        print(<span class="string">"Starting iterations..."</span>)</span><br><span class="line">    itr = <span class="number">0</span></span><br><span class="line">    labels = <span class="literal">None</span></span><br><span class="line">    converged = <span class="literal">False</span></span><br><span class="line">    cost = np.Inf</span><br><span class="line">    <span class="keyword">while</span> itr &lt;= max_iter <span class="keyword">and</span> <span class="keyword">not</span> converged:</span><br><span class="line">        itr += <span class="number">1</span></span><br><span class="line">        centroids, moves = _k_prototypes_iter(Xnum, Xcat, centroids,</span><br><span class="line">                                              cl_attr_sum, cl_memb_sum, cl_attr_freq,</span><br><span class="line">                                              membship, num_dissim, cat_dissim, gamma,</span><br><span class="line">                                              random_state)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># All points seen in this iteration</span></span><br><span class="line">        labels, ncost = _labels_cost(Xnum, Xcat, centroids,</span><br><span class="line">                                     num_dissim, cat_dissim, gamma, membship)</span><br><span class="line">        converged = (moves == <span class="number">0</span>) <span class="keyword">or</span> (ncost &gt;= cost)</span><br><span class="line">        cost = ncost</span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            print(<span class="string">"Run: &#123;&#125;, iteration: &#123;&#125;/&#123;&#125;, moves: &#123;&#125;, ncost: &#123;&#125;"</span></span><br><span class="line">                  .format(init_no + <span class="number">1</span>, itr, max_iter, moves, ncost))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> centroids, labels, cost, itr</span><br></pre></td></tr></table></figure>
      

      
        <div class="page-reward">
          <a href="javascript:;" class="page-reward-btn tooltip-top">
            <div class="tooltip tooltip-east">
            <span class="tooltip-item">
              赏
            </span>
            <span class="tooltip-content">
              <span class="tooltip-text">
                <span class="tooltip-inner">
                  <p class="reward-p"><i class="icon icon-quo-left"></i>Thanks for your donate.<i class="icon icon-quo-right"></i></p>
                  <div class="reward-box">
                    
                    <div class="reward-box-item">
                      <img class="reward-img" src="/images/alipay.jpeg">
                      <span class="reward-type">支付宝</span>
                    </div>
                    
                    
                  </div>
                </span>
              </span>
            </span>
          </div>
          </a>
        </div>
      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">Cluster</a>
        		</li>
      		
		</ul>
	</div>

      

      

      
        
<div class="share-btn share-icons tooltip-left">
  <div class="tooltip tooltip-east">
    <span class="tooltip-item">
      <a href="javascript:;" class="share-sns share-outer">
        <i class="icon icon-share"></i>
      </a>
    </span>
    <span class="tooltip-content">
      <div class="share-wrap">
        <div class="share-icons">
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="icon icon-weibo"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="icon icon-weixin"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="icon icon-qq"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="icon icon-douban"></i>
          </a>
          <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a>
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="icon icon-facebook"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="icon icon-twitter"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="icon icon-google"></i>
          </a>
        </div>
      </div>
    </span>
  </div>
</div>

<div class="page-modal wx-share js-wx-box">
    <a class="close js-modal-close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="http://s.jiathis.com/qrcode.php?url=http://chenson.cc/2018/11/27/聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探/" alt="微信分享二维码">
    </div>
</div>

<div class="mask js-mask"></div>
      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
    <a href="/2018/12/01/拒绝图床，从我做起/" id="article-nav-newer" class="article-nav-link-wrap">
      <i class="icon-circle-left"></i>
      <div class="article-nav-title">
        
          拒绝图床，从我做起
        
      </div>
    </a>
  
  
    <a href="/2018/11/20/关于Python的Mixin模式初探/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">关于Python的Mixin模式初探</div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>






  
  <div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探" data-title="聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探" data-url="http://chenson.cc/2018/11/27/聚类算法：K-Means及扩展算法K-Modes、K-Prototype初探/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>

  







          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">

    	<div class="footer-left">
    		&copy; 2019 Chenson Van
    	</div>
      
      <div class="footer-right">
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
        </script>

        <span id="busuanzi_container_site_pv">
        本站总访问量<span id="busuanzi_value_site_pv"></span>次
        </span>

        <span id="busuanzi_container_page_pv">
        本文总阅读量<span id="busuanzi_value_page_pv"></span>次
        </span>

      </div>

    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		root: "/",
		innerArchive: true,
		showTags: true
	}
</script>

<script>!function(t){function n(r){if(e[r])return e[r].exports;var o=e[r]={exports:{},id:r,loaded:!1};return t[r].call(o.exports,o,o.exports,n),o.loaded=!0,o.exports}var e={};return n.m=t,n.c=e,n.p="./",n(0)}([function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}function o(t,n){var e=/\/|index.html/g;return t.replace(e,"")===n.replace(e,"")}function i(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,e=0,r=t.length;e<r;e++){var i=t[e];o(n,i.getAttribute("href"))&&(0,d.default)(i,"active")}}function u(t){for(var n=t.offsetLeft,e=t.offsetParent;null!==e;)n+=e.offsetLeft,e=e.offsetParent;return n}function f(t){for(var n=t.offsetTop,e=t.offsetParent;null!==e;)n+=e.offsetTop,e=e.offsetParent;return n}function c(t,n,e,r,o){var i=u(t),c=f(t)-n;if(c-e<=o){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,h.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(e||c)+"px",a.style.left=i+"px",a.style.zIndex=r||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");c(t,document.body.scrollTop,-63,2,0),c(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}function l(){x.default.versions.mobile&&window.screen.width<800&&(i(),s())}var p=e(71),d=r(p),v=e(72),y=(r(v),e(84)),h=r(y),b=e(69),x=r(b),m=e(75),g=r(m),w=e(70);l(),(0,w.addLoadEvent)(function(){g.default.init()}),t.exports={}},function(t,n){var e=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=e)},function(t,n){var e={}.hasOwnProperty;t.exports=function(t,n){return e.call(t,n)}},function(t,n,e){var r=e(49),o=e(15);t.exports=function(t){return r(o(t))}},function(t,n,e){t.exports=!e(8)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,e){var r=e(6),o=e(12);t.exports=e(4)?function(t,n,e){return r.f(t,n,o(1,e))}:function(t,n,e){return t[n]=e,t}},function(t,n,e){var r=e(10),o=e(30),i=e(24),u=Object.defineProperty;n.f=e(4)?Object.defineProperty:function(t,n,e){if(r(t),n=i(n,!0),r(e),o)try{return u(t,n,e)}catch(t){}if("get"in e||"set"in e)throw TypeError("Accessors not supported!");return"value"in e&&(t[n]=e.value),t}},function(t,n,e){var r=e(22)("wks"),o=e(13),i=e(1).Symbol,u="function"==typeof i,f=t.exports=function(t){return r[t]||(r[t]=u&&i[t]||(u?i:o)("Symbol."+t))};f.store=r},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,e){var r=e(35),o=e(16);t.exports=Object.keys||function(t){return r(t,o)}},function(t,n,e){var r=e(11);t.exports=function(t){if(!r(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var e=0,r=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++e+r).toString(36))}},function(t,n){var e=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=e)},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,e){var r=e(6).f,o=e(2),i=e(7)("toStringTag");t.exports=function(t,n,e){t&&!o(t=e?t:t.prototype,i)&&r(t,i,{configurable:!0,value:n})}},function(t,n,e){var r=e(22)("keys"),o=e(13);t.exports=function(t){return r[t]||(r[t]=o(t))}},function(t,n,e){var r=e(1),o="__core-js_shared__",i=r[o]||(r[o]={});t.exports=function(t){return i[t]||(i[t]={})}},function(t,n){var e=Math.ceil,r=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?r:e)(t)}},function(t,n,e){var r=e(11);t.exports=function(t,n){if(!r(t))return t;var e,o;if(n&&"function"==typeof(e=t.toString)&&!r(o=e.call(t)))return o;if("function"==typeof(e=t.valueOf)&&!r(o=e.call(t)))return o;if(!n&&"function"==typeof(e=t.toString)&&!r(o=e.call(t)))return o;throw TypeError("Can't convert object to primitive value")}},function(t,n,e){var r=e(1),o=e(14),i=e(18),u=e(26),f=e(6).f;t.exports=function(t){var n=o.Symbol||(o.Symbol=i?{}:r.Symbol||{});"_"==t.charAt(0)||t in n||f(n,t,{value:u.f(t)})}},function(t,n,e){n.f=e(7)},function(t,n,e){var r=e(1),o=e(14),i=e(46),u=e(5),f="prototype",c=function(t,n,e){var a,s,l,p=t&c.F,d=t&c.G,v=t&c.S,y=t&c.P,h=t&c.B,b=t&c.W,x=d?o:o[n]||(o[n]={}),m=x[f],g=d?r:v?r[n]:(r[n]||{})[f];d&&(e=n);for(a in e)s=!p&&g&&void 0!==g[a],s&&a in x||(l=s?g[a]:e[a],x[a]=d&&"function"!=typeof g[a]?e[a]:h&&s?i(l,r):b&&g[a]==l?function(t){var n=function(n,e,r){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,e)}return new t(n,e,r)}return t.apply(this,arguments)};return n[f]=t[f],n}(l):y&&"function"==typeof l?i(Function.call,l):l,y&&((x.virtual||(x.virtual={}))[a]=l,t&c.R&&m&&!m[a]&&u(m,a,l)))};c.F=1,c.G=2,c.S=4,c.P=8,c.B=16,c.W=32,c.U=64,c.R=128,t.exports=c},function(t,n){var e={}.toString;t.exports=function(t){return e.call(t).slice(8,-1)}},function(t,n,e){var r=e(11),o=e(1).document,i=r(o)&&r(o.createElement);t.exports=function(t){return i?o.createElement(t):{}}},function(t,n,e){t.exports=!e(4)&&!e(8)(function(){return 7!=Object.defineProperty(e(29)("div"),"a",{get:function(){return 7}}).a})},function(t,n,e){"use strict";var r=e(18),o=e(27),i=e(36),u=e(5),f=e(2),c=e(17),a=e(51),s=e(20),l=e(58),p=e(7)("iterator"),d=!([].keys&&"next"in[].keys()),v="@@iterator",y="keys",h="values",b=function(){return this};t.exports=function(t,n,e,x,m,g,w){a(e,n,x);var O,S,_,j=function(t){if(!d&&t in A)return A[t];switch(t){case y:return function(){return new e(this,t)};case h:return function(){return new e(this,t)}}return function(){return new e(this,t)}},P=n+" Iterator",E=m==h,M=!1,A=t.prototype,T=A[p]||A[v]||m&&A[m],L=T||j(m),N=m?E?j("entries"):L:void 0,C="Array"==n?A.entries||T:T;if(C&&(_=l(C.call(new t)),_!==Object.prototype&&(s(_,P,!0),r||f(_,p)||u(_,p,b))),E&&T&&T.name!==h&&(M=!0,L=function(){return T.call(this)}),r&&!w||!d&&!M&&A[p]||u(A,p,L),c[n]=L,c[P]=b,m)if(O={values:E?L:j(h),keys:g?L:j(y),entries:N},w)for(S in O)S in A||i(A,S,O[S]);else o(o.P+o.F*(d||M),n,O);return O}},function(t,n,e){var r=e(10),o=e(55),i=e(16),u=e(21)("IE_PROTO"),f=function(){},c="prototype",a=function(){var t,n=e(29)("iframe"),r=i.length,o="<",u=">";for(n.style.display="none",e(48).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write(o+"script"+u+"document.F=Object"+o+"/script"+u),t.close(),a=t.F;r--;)delete a[c][i[r]];return a()};t.exports=Object.create||function(t,n){var e;return null!==t?(f[c]=r(t),e=new f,f[c]=null,e[u]=t):e=a(),void 0===n?e:o(e,n)}},function(t,n,e){var r=e(35),o=e(16).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return r(t,o)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,e){var r=e(2),o=e(3),i=e(45)(!1),u=e(21)("IE_PROTO");t.exports=function(t,n){var e,f=o(t),c=0,a=[];for(e in f)e!=u&&r(f,e)&&a.push(e);for(;n.length>c;)r(f,e=n[c++])&&(~i(a,e)||a.push(e));return a}},function(t,n,e){t.exports=e(5)},function(t,n,e){var r=e(15);t.exports=function(t){return Object(r(t))}},function(t,n,e){t.exports={default:e(41),__esModule:!0}},function(t,n,e){t.exports={default:e(42),__esModule:!0}},function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var o=e(39),i=r(o),u=e(38),f=r(u),c="function"==typeof f.default&&"symbol"==typeof i.default?function(t){return typeof t}:function(t){return t&&"function"==typeof f.default&&t.constructor===f.default&&t!==f.default.prototype?"symbol":typeof t};n.default="function"==typeof f.default&&"symbol"===c(i.default)?function(t){return"undefined"==typeof t?"undefined":c(t)}:function(t){return t&&"function"==typeof f.default&&t.constructor===f.default&&t!==f.default.prototype?"symbol":"undefined"==typeof t?"undefined":c(t)}},function(t,n,e){e(65),e(63),e(66),e(67),t.exports=e(14).Symbol},function(t,n,e){e(64),e(68),t.exports=e(26).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,e){var r=e(3),o=e(61),i=e(60);t.exports=function(t){return function(n,e,u){var f,c=r(n),a=o(c.length),s=i(u,a);if(t&&e!=e){for(;a>s;)if(f=c[s++],f!=f)return!0}else for(;a>s;s++)if((t||s in c)&&c[s]===e)return t||s||0;return!t&&-1}}},function(t,n,e){var r=e(43);t.exports=function(t,n,e){if(r(t),void 0===n)return t;switch(e){case 1:return function(e){return t.call(n,e)};case 2:return function(e,r){return t.call(n,e,r)};case 3:return function(e,r,o){return t.call(n,e,r,o)}}return function(){return t.apply(n,arguments)}}},function(t,n,e){var r=e(9),o=e(34),i=e(19);t.exports=function(t){var n=r(t),e=o.f;if(e)for(var u,f=e(t),c=i.f,a=0;f.length>a;)c.call(t,u=f[a++])&&n.push(u);return n}},function(t,n,e){t.exports=e(1).document&&document.documentElement},function(t,n,e){var r=e(28);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==r(t)?t.split(""):Object(t)}},function(t,n,e){var r=e(28);t.exports=Array.isArray||function(t){return"Array"==r(t)}},function(t,n,e){"use strict";var r=e(32),o=e(12),i=e(20),u={};e(5)(u,e(7)("iterator"),function(){return this}),t.exports=function(t,n,e){t.prototype=r(u,{next:o(1,e)}),i(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,e){var r=e(9),o=e(3);t.exports=function(t,n){for(var e,i=o(t),u=r(i),f=u.length,c=0;f>c;)if(i[e=u[c++]]===n)return e}},function(t,n,e){var r=e(13)("meta"),o=e(11),i=e(2),u=e(6).f,f=0,c=Object.isExtensible||function(){return!0},a=!e(8)(function(){return c(Object.preventExtensions({}))}),s=function(t){u(t,r,{value:{i:"O"+ ++f,w:{}}})},l=function(t,n){if(!o(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!i(t,r)){if(!c(t))return"F";if(!n)return"E";s(t)}return t[r].i},p=function(t,n){if(!i(t,r)){if(!c(t))return!0;if(!n)return!1;s(t)}return t[r].w},d=function(t){return a&&v.NEED&&c(t)&&!i(t,r)&&s(t),t},v=t.exports={KEY:r,NEED:!1,fastKey:l,getWeak:p,onFreeze:d}},function(t,n,e){var r=e(6),o=e(10),i=e(9);t.exports=e(4)?Object.defineProperties:function(t,n){o(t);for(var e,u=i(n),f=u.length,c=0;f>c;)r.f(t,e=u[c++],n[e]);return t}},function(t,n,e){var r=e(19),o=e(12),i=e(3),u=e(24),f=e(2),c=e(30),a=Object.getOwnPropertyDescriptor;n.f=e(4)?a:function(t,n){if(t=i(t),n=u(n,!0),c)try{return a(t,n)}catch(t){}if(f(t,n))return o(!r.f.call(t,n),t[n])}},function(t,n,e){var r=e(3),o=e(33).f,i={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],f=function(t){try{return o(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==i.call(t)?f(t):o(r(t))}},function(t,n,e){var r=e(2),o=e(37),i=e(21)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=o(t),r(t,i)?t[i]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,e){var r=e(23),o=e(15);t.exports=function(t){return function(n,e){var i,u,f=String(o(n)),c=r(e),a=f.length;return c<0||c>=a?t?"":void 0:(i=f.charCodeAt(c),i<55296||i>56319||c+1===a||(u=f.charCodeAt(c+1))<56320||u>57343?t?f.charAt(c):i:t?f.slice(c,c+2):(i-55296<<10)+(u-56320)+65536)}}},function(t,n,e){var r=e(23),o=Math.max,i=Math.min;t.exports=function(t,n){return t=r(t),t<0?o(t+n,0):i(t,n)}},function(t,n,e){var r=e(23),o=Math.min;t.exports=function(t){return t>0?o(r(t),9007199254740991):0}},function(t,n,e){"use strict";var r=e(44),o=e(52),i=e(17),u=e(3);t.exports=e(31)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,e=this._i++;return!t||e>=t.length?(this._t=void 0,o(1)):"keys"==n?o(0,e):"values"==n?o(0,t[e]):o(0,[e,t[e]])},"values"),i.Arguments=i.Array,r("keys"),r("values"),r("entries")},function(t,n){},function(t,n,e){"use strict";var r=e(59)(!0);e(31)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,e=this._i;return e>=n.length?{value:void 0,done:!0}:(t=r(n,e),this._i+=t.length,{value:t,done:!1})})},function(t,n,e){"use strict";var r=e(1),o=e(2),i=e(4),u=e(27),f=e(36),c=e(54).KEY,a=e(8),s=e(22),l=e(20),p=e(13),d=e(7),v=e(26),y=e(25),h=e(53),b=e(47),x=e(50),m=e(10),g=e(3),w=e(24),O=e(12),S=e(32),_=e(57),j=e(56),P=e(6),E=e(9),M=j.f,A=P.f,T=_.f,L=r.Symbol,N=r.JSON,C=N&&N.stringify,k="prototype",F=d("_hidden"),q=d("toPrimitive"),I={}.propertyIsEnumerable,B=s("symbol-registry"),D=s("symbols"),W=s("op-symbols"),H=Object[k],K="function"==typeof L,R=r.QObject,J=!R||!R[k]||!R[k].findChild,U=i&&a(function(){return 7!=S(A({},"a",{get:function(){return A(this,"a",{value:7}).a}})).a})?function(t,n,e){var r=M(H,n);r&&delete H[n],A(t,n,e),r&&t!==H&&A(H,n,r)}:A,G=function(t){var n=D[t]=S(L[k]);return n._k=t,n},$=K&&"symbol"==typeof L.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof L},z=function(t,n,e){return t===H&&z(W,n,e),m(t),n=w(n,!0),m(e),o(D,n)?(e.enumerable?(o(t,F)&&t[F][n]&&(t[F][n]=!1),e=S(e,{enumerable:O(0,!1)})):(o(t,F)||A(t,F,O(1,{})),t[F][n]=!0),U(t,n,e)):A(t,n,e)},Y=function(t,n){m(t);for(var e,r=b(n=g(n)),o=0,i=r.length;i>o;)z(t,e=r[o++],n[e]);return t},Q=function(t,n){return void 0===n?S(t):Y(S(t),n)},X=function(t){var n=I.call(this,t=w(t,!0));return!(this===H&&o(D,t)&&!o(W,t))&&(!(n||!o(this,t)||!o(D,t)||o(this,F)&&this[F][t])||n)},V=function(t,n){if(t=g(t),n=w(n,!0),t!==H||!o(D,n)||o(W,n)){var e=M(t,n);return!e||!o(D,n)||o(t,F)&&t[F][n]||(e.enumerable=!0),e}},Z=function(t){for(var n,e=T(g(t)),r=[],i=0;e.length>i;)o(D,n=e[i++])||n==F||n==c||r.push(n);return r},tt=function(t){for(var n,e=t===H,r=T(e?W:g(t)),i=[],u=0;r.length>u;)!o(D,n=r[u++])||e&&!o(H,n)||i.push(D[n]);return i};K||(L=function(){if(this instanceof L)throw TypeError("Symbol is not a constructor!");var t=p(arguments.length>0?arguments[0]:void 0),n=function(e){this===H&&n.call(W,e),o(this,F)&&o(this[F],t)&&(this[F][t]=!1),U(this,t,O(1,e))};return i&&J&&U(H,t,{configurable:!0,set:n}),G(t)},f(L[k],"toString",function(){return this._k}),j.f=V,P.f=z,e(33).f=_.f=Z,e(19).f=X,e(34).f=tt,i&&!e(18)&&f(H,"propertyIsEnumerable",X,!0),v.f=function(t){return G(d(t))}),u(u.G+u.W+u.F*!K,{Symbol:L});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),et=0;nt.length>et;)d(nt[et++]);for(var nt=E(d.store),et=0;nt.length>et;)y(nt[et++]);u(u.S+u.F*!K,"Symbol",{for:function(t){return o(B,t+="")?B[t]:B[t]=L(t)},keyFor:function(t){if($(t))return h(B,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){J=!0},useSimple:function(){J=!1}}),u(u.S+u.F*!K,"Object",{create:Q,defineProperty:z,defineProperties:Y,getOwnPropertyDescriptor:V,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),N&&u(u.S+u.F*(!K||a(function(){var t=L();return"[null]"!=C([t])||"{}"!=C({a:t})||"{}"!=C(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!$(t)){for(var n,e,r=[t],o=1;arguments.length>o;)r.push(arguments[o++]);return n=r[1],"function"==typeof n&&(e=n),!e&&x(n)||(n=function(t,n){if(e&&(n=e.call(this,t,n)),!$(n))return n}),r[1]=n,C.apply(N,r)}}}),L[k][q]||e(5)(L[k],q,L[k].valueOf),l(L,"Symbol"),l(Math,"Math",!0),l(r.JSON,"JSON",!0)},function(t,n,e){e(25)("asyncIterator")},function(t,n,e){e(25)("observable")},function(t,n,e){e(62);for(var r=e(1),o=e(5),i=e(17),u=e(7)("toStringTag"),f=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],c=0;c<5;c++){var a=f[c],s=r[a],l=s&&s.prototype;l&&!l[u]&&o(l,u,a),i[a]=i.Array}},function(t,n){"use strict";var e={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&t.indexOf("KHTML")==-1,mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:t.indexOf("Safari")==-1,weixin:t.indexOf("MicroMessenger")==-1}}()};t.exports=e},function(t,n,e){"use strict";function r(t){return t&&t.__esModule?t:{default:t}}var o=e(40),i=r(o),u=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):o[t]||t}function n(t){return l[t]}var e=/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,r=/['<> "&]/g,o={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},f=/\u00a0/g,c=/<br\s*\/?>/gi,a=/\r?\n/g,s=/\s/g,l={};for(var p in o)l[o[p]]=p;return o["&apos;"]="'",l["'"]="&#39;",{encode:function(t){return t?(""+t).replace(r,n).replace(a,"<br/>").replace(s,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(c,"\n").replace(e,t).replace(f," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],e=0,r=t.length;r>e;e++)n.push(t.charCodeAt(e).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],e=0,r=t.length;r>e;e++)n.push(t.charCodeAt(e).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],e=0,r=t.length;r>e;e+=2)n.push(String.fromCharCode("0x"+t.slice(e,e+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,e=t.length;e>n;n++)t[n]=u.encodeObject(t[n]);else if("object"==("undefined"==typeof t?"undefined":(0,i.default)(t)))for(var r in t)t[r]=u.encodeObject(t[r]);else if("string"==typeof t)return u.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=u},function(t,n){function e(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=e},function(t,n){function e(t,n){if(t.classList)t.classList.remove(n);else{var e=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(e," ")}}t.exports=e},,,function(t,n){"use strict";function e(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){var n=document.querySelectorAll(".article-entry a:not(.article-more-a)");n.forEach(function(t){t.setAttribute("target","_blank")})}var e=document.querySelector("#js-aboutme");e&&0!==e.length&&(e.innerHTML=e.innerText)}t.exports={init:e}},,,,,,,,,function(t,n){function e(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var e=t.nextSibling;return e?t.parentNode.insertBefore(n,e):t.parentNode.appendChild(n)}t.exports=e}])</script><script src="/./main.2d7529.js"></script><script>!function(){var e=function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)};e("/slider.885efe.js")}()</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    }); 
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 50%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">Tags</a></li>
      
        
      
        
      
      <li style="width: 50%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">About Me</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">Python</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Numpy</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">Pandas</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">Machine Learning</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">SVM</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">Hadoop</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">MapReduce</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Algorithm</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">SQL</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Spark</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">Ensemble</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">PCA</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">线程</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">进程</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">同步异步IO</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">docker</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">PyTorch</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">Deep Learning</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">Jupyter</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">CNN</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">RNN</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">图数据库</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Neo4j</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">关系网络</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Wide&Deep</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">Pytorch</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">FTRL</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">hexo</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">Typora</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">Cluster</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">Big Data</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">MLR</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">jupyterhub</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">PySpark</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">读书笔记</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">智能营销</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">用户画像</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">Mac</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">Fiddler</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">Centos7</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Nvida</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">GPU</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">Auto-ML</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">推荐系统</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">FM</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">FFM</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">DeepFM</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">DCN</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">Genetic Algorithm</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">Metabase</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">BI报表</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">LBS</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Quant</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">优化算法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">TensorFlow</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">分布式</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br>1、在博客根目录（注意不是yilia根目录）执行以下命令：<br> npm i hexo-generator-json-content --save<br><br>
            2、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: true
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">喜欢纹身 喜欢喝酒 喜欢编程 喜欢摄影 喜欢独自旅行 也喜欢一个人看海</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]]}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>